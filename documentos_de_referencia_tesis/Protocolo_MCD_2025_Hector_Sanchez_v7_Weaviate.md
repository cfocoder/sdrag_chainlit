## UNIVERSIDAD DE GUADALAJARA

## CENTRO UNIVERSITARIO DE CIENCIAS ECON√ìMICO ADMINISTRATIVAS

## COORDINACI√ìN DE POSGRADO

## MAESTR√çA EN CIENCIA DE LOS DATOS

<!-- image -->

Protocolo de Investigaci√≥n  
Arquitectura RAG H√≠brida con Capa Sem√°ntica Determinista (SDRAG) para Reducir Alucinaciones Aritm√©ticas en Anal√≠tica Financiera (FP&A)

## P R E S E N T A

## HECTOR GABRIEL SANCHEZ PEREZ

Enero 19, 2026  
www.cfocoder.com  
hector@sanchezmx.com  
+52 (33) 1286-6700

<!-- image -->

<!-- image -->

---

## 1. T√≠tulo

**Arquitectura RAG H√≠brida con Capa Sem√°ntica Determinista para Reducir Alucinaciones Aritm√©ticas en Sistemas de IA Generativa aplicados a Anal√≠tica Financiera (FP&A)**

---

## 2. Planteamiento del Problema

Los Grandes Modelos de Lenguaje (LLMs) han demostrado capacidades excepcionales en tareas de procesamiento de lenguaje natural, pero presentan limitaciones cr√≠ticas al interactuar con datos estructurados, especialmente en contextos financieros donde la precisi√≥n num√©rica es imperativa.

### 2.1 Descripci√≥n del Problema

La integraci√≥n de LLMs en procesos de Planificaci√≥n y An√°lisis Financiero (FP&A) enfrenta desaf√≠os fundamentales que limitan su adopci√≥n en entornos corporativos:

1. **Alucinaciones Aritm√©ticas**: Los LLMs, por su naturaleza estoc√°stica, generan c√°lculos incorrectos y resultados financieros inexactos. La literatura cient√≠fica documenta tasas de error del ~40% en tareas Text-to-SQL sin asistencia estructural (Spider Benchmark baseline).

2. **Degradaci√≥n en Text-to-SQL Directo**: Estudios recientes (FinanceBench 2023) reportan tasas de falla superiores al 80% en preguntas financieras que requieren precisi√≥n num√©rica con GPT-4-Turbo y RAG tradicional, evidenciando la insuficiencia de los enfoques vectoriales puros.

3. **Opacidad en Decisiones de Ejecuci√≥n**: Los sistemas actuales (OpenWebUI, copilots gen√©ricos) delegan en el LLM la decisi√≥n de **qu√© ejecutar y c√≥mo**, generando rutas de ejecuci√≥n impl√≠citas y no auditables.

4. **Falta de Trazabilidad**: La ausencia de registro expl√≠cito de pasos de ejecuci√≥n (SQL generado, datos recuperados, c√°lculos intermedios) impide la validaci√≥n forense necesaria en auditor√≠as financieras.

### 2.2 Pregunta de Investigaci√≥n

¬øPuede una arquitectura de **ejecuci√≥n determinista con explicaci√≥n asistida por lenguaje** (SDRAG) reducir significativamente las alucinaciones aritm√©ticas en sistemas de IA generativa aplicados a anal√≠tica financiera, comparada con enfoques Text-to-SQL directos y RAG tradicionales?

**Pregunta Secundaria**: ¬øEs el paradigma Headless BI (capa sem√°ntica como API + UI intercambiable) una arquitectura viable para garantizar reproducibilidad en experimentos acad√©micos y aplicabilidad en producci√≥n simult√°neamente?

### 2.3 Delimitaci√≥n del Alcance

- **Temporal**: Desarrollo durante 4 semestres acad√©micos (2025-2027).
- **Espacial**: Infraestructura distribuida h√≠brida (Oracle Cloud ARM64 + laboratorio local x86 en Guadalajara, M√©xico).
- **T√©cnica**: Framework SDRAG con validaci√≥n mediante benchmarks est√°ndar (Spider, BIRD, FinQA, TAT-QA, FinanceBench).
- **Dominio**: Anal√≠tica financiera (FP&A) como caso de estudio, con arquitectura agn√≥stica al dominio para permitir generalizaci√≥n.
- **Limitaciones Expl√≠citas**: 
  - No implementa alta disponibilidad (HA) ni replicaci√≥n multi-nodo.
  - Infraestructura limitada a 3 nodos f√≠sicos disponibles.
  - Prioriza precisi√≥n y trazabilidad sobre escalabilidad industrial completa.

---

## 3. Justificaci√≥n

### 3.1 Relevancia Acad√©mica

Este proyecto contribuye al campo emergente de **arquitecturas de IA con ejecuci√≥n determin√≠stica** al proponer un modelo que combina:

- **Generaci√≥n flexible** (LLMs) para interpretaci√≥n de lenguaje natural y generaci√≥n de explicaciones post-c√°lculo.
- **Ejecuci√≥n determin√≠stica** (Capa Sem√°ntica v√≠a Cube Core) para garantizar precisi√≥n num√©rica y reproducibilidad.
- **Clasificaci√≥n expl√≠cita** (n8n con reglas determin√≠sticas) para control de flujo auditable.

**Nota conceptual**: El determinismo se aplica a nivel de **ejecuci√≥n de c√°lculos**, no a la generaci√≥n ling√º√≠stica del LLM. El modelo estoc√°stico solo genera explicaciones sobre resultados ya validados.

**Vac√≠o en la Literatura**: La investigaci√≥n actual en RAG se enfoca en recuperaci√≥n de documentos no estructurados. Existe escasa literatura sobre arquitecturas de producci√≥n para LLMs en contextos de alta sensibilidad num√©rica (finanzas, salud, infraestructura cr√≠tica) que garanticen trazabilidad completa.

**Diferenciaci√≥n vs. Estado del Arte**:

| Dimensi√≥n | RAG Tradicional | SDRAG (Propuesto) |
|-----------|-----------------|-------------------|
| **Generaci√≥n de n√∫meros** | LLM genera valores | ‚ùå Prohibido - Solo capa sem√°ntica |
| **SQL** | Generado por LLM (estoc√°stico) | ‚úÖ Determinista v√≠a Cube Core |
| **Ruta de ejecuci√≥n** | Decidida por LLM | ‚úÖ Reglas + Clasificador ligero (n8n) |
| **Explicaci√≥n** | LLM genera explicaci√≥n + datos | ‚úÖ Dify solo explica datos validados |
| **Contexto documental** | M√∫ltiples vector stores | ‚úÖ Weaviate √∫nica (simplificaci√≥n deliberada) |
| **Trazabilidad** | Parcial (prompt ‚Üí respuesta) | ‚úÖ Completa (SQL + datos + pasos) |
| **Reproducibilidad** | Baja (temperatura ‚â† 0) | ‚úÖ Alta (mismo input ‚Üí mismo output) |
| **Riesgo de alucinaci√≥n aritm√©tica** | Alto (~40% error) | ‚úÖ Bajo por dise√±o arquitect√≥nico |

**Nota sobre Dify**: En SDRAG, Dify act√∫a exclusivamente como **capa de explicaci√≥n post-c√°lculo**. Recibe resultados ya validados por Cube Core y genera explicaciones en lenguaje natural sin modificar datos ni participar en decisiones de enrutamiento. Esta separaci√≥n estricta es clave para mantener el determinismo arquitect√≥nico.

### 3.2 Relevancia Profesional

El investigador posee 30+ a√±os de experiencia en anal√≠tica financiera corporativa (KPMG, Motorola, HP, OpenText, Weave Communications), proporcionando:

- **Conocimiento del dominio** para validar casos de uso realistas de FP&A.
- **Acceso a procesos** para fundamentar requisitos t√©cnicos (cierres contables, an√°lisis de varianza, forecasting).
- **Capacidad de implementaci√≥n** en infraestructura auto-hospedada con presupuesto acad√©mico (~$0-150 USD).

### 3.3 Impacto Esperado

**Sector Acad√©mico**:
- Establecimiento de metodolog√≠a reproducible para evaluaci√≥n de LLMs en datos estructurados.
- Protocolo de m√©tricas expl√≠cito (Execution Accuracy, Query Routing Accuracy, Numerical Hallucination Rate, Traceability Completeness, Explanation Consistency) que otros investigadores pueden replicar.
- Contribuci√≥n al estado del arte en arquitecturas RAG h√≠bridas.

**Sector Empresarial**:
- Reducci√≥n de costos de infraestructura (arquitectura auto-hospedada vs. servicios cloud propietarios).
- Democratizaci√≥n de anal√≠tica avanzada para PyMEs mediante software open-source.
- **Valor operativo verificable**: Eliminaci√≥n de errores aritm√©ticos, consistencia en c√°lculos, trazabilidad completa, reducci√≥n de retrabajo en validaci√≥n manual.

---

## 4. Antecedentes / Marco Te√≥rico

### 4.1 Estado del Arte: Text-to-SQL

Los sistemas Text-to-SQL permiten consultar bases de datos usando lenguaje natural. Los enfoques tradicionales se clasifican en:

**Modelos Directos (LLM ‚Üí SQL)**:
- Ventajas: Simplicidad arquitectural, baja latencia.
- Limitaciones: Tasa de error ~40% (Spider), incapacidad de manejar esquemas complejos (BIRD 33.4 GB con datos "sucios").

**RAG Tradicional (LLM + Vectores)**:
- Ventajas: Contexto extendido, recuperaci√≥n de ejemplos similares.
- Limitaciones: FinanceBench reporta 81% de falla en c√°lculos financieros, evidenciando que embeddings solos no garantizan precisi√≥n aritm√©tica.

### 4.2 Capas Sem√°nticas (Semantic Layers): El √Årbitro Determinista

**Definici√≥n**: Una capa sem√°ntica abstrae la complejidad de bases de datos, exponiendo m√©tricas de negocio estandarizadas mediante APIs. Act√∫a como "Single Source of Truth" (SSOT).

**Tecnolog√≠as Principales**:
- **Cube Core** (Open Source): Define m√©tricas como c√≥digo (YAML/JavaScript), genera SQL optimizado, provee caching y pre-aggregations nativas.
- **dbt Semantic Layer**: Enfoque declarativo con materializaci√≥n incremental.
- **MetricFlow** (dbt Labs): Define m√©tricas como objetos de primera clase.

**Ventaja para LLMs**: El LLM consume un cat√°logo simplificado de m√©tricas (e.g., "Revenue", "COGS", "EBITDA") en lugar de tablas crudas, reduciendo la superficie de error.

**Justificaci√≥n de Cube Core**:
1. Caching y pre-aggregations nativas (Redis).
2. API headless lista para consumo LLM (REST/GraphQL).
3. M√©tricas versionadas y auditables (Git-based).
4. Separaci√≥n clara entre definici√≥n sem√°ntica y ejecuci√≥n SQL.

### 4.3 Plataformas LLM de Producci√≥n: Dify como Capa de Explicaci√≥n

**Dify** es una plataforma open-source para desarrollo de aplicaciones LLM que provee:
- Gesti√≥n de prompts versionados
- Orquestaci√≥n de flujos LLM
- Observabilidad y m√©tricas de inferencia
- Soporte multi-modelo (OpenAI, Anthropic, modelos locales)

**Rol en SDRAG**: Dify se utiliza exclusivamente como **Language Explanation Service**. Su funci√≥n es transformar resultados ya calculados y validados por componentes deterministas (Cube Core, DuckDB) en explicaciones comprensibles para el usuario final.

**Principio Central**: Dify **no participa en**:
- Toma de decisiones o clasificaci√≥n de consultas (responsabilidad de n8n)
- Generaci√≥n de SQL o queries (responsabilidad de Cube Core)
- Selecci√≥n de rutas de ejecuci√≥n (responsabilidad de n8n)
- Validaci√≥n de resultados num√©ricos (responsabilidad de Cube Core + DuckDB)

Esta separaci√≥n garantiza reproducibilidad, auditabilidad y alineaci√≥n con los principios de SDRAG.

### 4.4 Weaviate: Base de Datos Vectorial √önica para RAG Documental

**Weaviate** es una base de datos vectorial open-source que combina b√∫squeda por similitud sem√°ntica (vectorial) con b√∫squeda por palabras clave (BM25). En SDRAG, Weaviate act√∫a como la **√∫nica base de datos vectorial** del proyecto, responsable del RAG sobre documentos no estructurados.

#### Justificaci√≥n de Weaviate como √önica Base Vectorial

La decisi√≥n de utilizar una √∫nica base de datos vectorial responde a principios de **reducci√≥n de complejidad innecesaria** alineados con los objetivos de precisi√≥n, trazabilidad y control del razonamiento:

1. **Simplicidad arquitect√≥nica**: Un √∫nico punto de acceso para contexto documental elimina la necesidad de l√≥gica de routing entre m√∫ltiples vector stores.

2. **Trazabilidad mejorada**: Toda consulta documental se resuelve en un √∫nico sistema, facilitando auditor√≠a y debugging.

3. **Mantenimiento reducido**: Un solo sistema vectorial implica menor overhead operativo (backups, actualizaciones, monitoreo).

4. **Consistencia de √≠ndices**: Sin riesgo de desincronizaci√≥n entre m√∫ltiples bases de datos vectoriales.

5. **Recursos limitados**: La infraestructura acad√©mica (3 nodos) se beneficia de la consolidaci√≥n de servicios.

#### Rol de Weaviate en SDRAG

Weaviate **S√ç es responsable de**:
- Almacenar y recuperar embeddings de documentos no estructurados (PDFs, Markdown, documentaci√≥n t√©cnica).
- Proveer b√∫squeda h√≠brida (vectorial + BM25) para maximizar relevancia de recuperaci√≥n.
- Almacenar definiciones de m√©tricas, reglas de negocio y documentaci√≥n de Cube Core.
- Soportar relaciones impl√≠citas entre objetos (GraphRAG ligero) mediante referencias cruzadas entre clases.

Weaviate **NO participa en**:
- Generaci√≥n de valores num√©ricos (responsabilidad exclusiva de Cube Core).
- C√°lculos aritm√©ticos o agregaciones.
- Ejecuci√≥n de SQL o consultas anal√≠ticas.
- Toma de decisiones de enrutamiento (responsabilidad de n8n).

**Principio Cr√≠tico**: Los valores num√©ricos **nunca provienen de Weaviate**. Weaviate proporciona contexto sem√°ntico (definiciones, ejemplos, documentaci√≥n), no resultados de c√°lculo. En caso de conflicto entre contexto documental (Weaviate) y resultados estructurados (Cube Core), **siempre prevalece Cube Core**.

#### GraphRAG Impl√≠cito en Weaviate

Weaviate permite modelar relaciones entre objetos mediante referencias cruzadas entre clases, habilitando un **GraphRAG ligero** sin necesidad de una base de datos de grafos dedicada:

**Clases en Weaviate**:
- `Document`: Documentos fuente (PDFs, reportes, papers).
- `Chunk`: Fragmentos sem√°nticos extra√≠dos de documentos.
- `MetricDefinition`: Definiciones de m√©tricas de Cube Core.
- `BusinessRule`: Reglas de c√°lculo y pol√≠ticas de negocio.

**Relaciones (Cross-references)**:
- `Chunk` ‚Üí `belongsTo` ‚Üí `Document`
- `MetricDefinition` ‚Üí `referencedIn` ‚Üí `Document`
- `Chunk` ‚Üí `defines` ‚Üí `MetricDefinition`
- `BusinessRule` ‚Üí `appliesTo` ‚Üí `MetricDefinition`

Esta estructura permite consultas de tipo:
- "¬øQu√© documentos definen la m√©trica EBITDA?"
- "¬øQu√© reglas de negocio aplican a Revenue Recognition?"
- "¬øEn qu√© secci√≥n del reporte se menciona esta m√©trica?"

**Limitaci√≥n deliberada**: El GraphRAG en Weaviate se limita a **1-2 saltos** de profundidad. Consultas de razonamiento multi-hop complejo quedan fuera del alcance de esta investigaci√≥n, priorizando la **simplicidad verificable** sobre la sofisticaci√≥n arquitect√≥nica.

### 4.5 RAG sobre Documentos No Estructurados: Alcance y Limitaciones

El uso de RAG en SDRAG se limita **exclusivamente** a documentos no estructurados y cumple un rol **estrictamente auxiliar**:

#### Tipos de Documentos Indexados en Weaviate

| Tipo de Documento | Prop√≥sito en SDRAG | Ejemplo |
|-------------------|-------------------|---------|
| PDFs financieros | Contexto explicativo, referencias | Annual Report 2024.pdf |
| Markdown / Documentaci√≥n | Definiciones, metodolog√≠as | metric_definitions.md |
| Documentaci√≥n t√©cnica | Contexto de implementaci√≥n | cube_model_docs.md |
| Reglas de negocio | Pol√≠ticas de c√°lculo | revenue_recognition_policy.md |
| Papers de investigaci√≥n | Marco te√≥rico, referencias | FinanceBench_2023.pdf |

#### Consultas que S√ç se Resuelven con RAG (Weaviate)

- "¬øC√≥mo se define el margen bruto seg√∫n las pol√≠ticas de la empresa?"
- "¬øQu√© dice el reporte anual sobre revenue recognition?"
- "¬øCu√°l es la metodolog√≠a de c√°lculo de EBITDA documentada?"
- "¬øQu√© secciones del reporte mencionan amortizaci√≥n?"

#### Consultas que NO se Resuelven con RAG

- ‚ùå "¬øCu√°l fue el EBITDA de Q3 2024?" ‚Üí **Cube Core**
- ‚ùå "¬øCu√°nto creci√≥ el revenue YoY?" ‚Üí **Cube Core**
- ‚ùå "Calcula el margen operativo" ‚Üí **Cube Core**
- ‚ùå "¬øCu√°l es el total de gastos?" ‚Üí **Cube Core**

**Regla fundamental**: Toda consulta que requiera un **valor num√©rico como respuesta** se resuelve exclusivamente mediante Cube Core. Weaviate proporciona **contexto para explicar** esos valores, nunca los valores mismos.

### 4.6 Benchmarks de Validaci√≥n

**Text-to-SQL Benchmarks**:
- **Spider (2018)**: 10,181 pares pregunta-SQL, 200 bases de datos (~5 GB). Baseline: ~40% Execution Accuracy sin capa sem√°ntica.
- **BIRD (2023)**: 12,751 ejemplos, 95 bases de datos (33.4 GB). Dataset realista con datos "sucios" y conocimiento externo.
- **WikiSQL (2017)**: 80,654 ejemplos, 24,241 tablas (~3 GB). Queries SQL simples (SELECT + WHERE).

**Financial Reasoning Benchmarks**:
- **FinQA (2021)**: 8,281 preguntas sobre reportes financieros (~1 GB), requiriendo operaciones aritm√©ticas multi-paso.
- **TAT-QA (2021)**: 16,552 preguntas sobre 2,757 reportes (~2 GB). QA h√≠brido (tablas + texto). Human performance: 84.1% F1.
- **FinanceBench (2023)**: 150 ejemplos human-annotated (~500 MB). Revela que GPT-4-Turbo con RAG falla 81% de preguntas financieras.
- **ConvFinQA (2022)**: QA conversacional financiero (~800 MB), eval√∫a razonamiento multi-hop.

**Table Reasoning Benchmarks**:
- **WikiTableQuestions (2015)**: Preguntas complejas sobre tablas (~1 GB).
- **SQA (2017)**: 6,066 secuencias de preguntas (~500 MB).

**Almacenamiento Total Estimado**: ~80-95 GB (Parquet + embeddings) en DuckLake.

### 4.7 Procesamiento de Documentos Financieros: Chunking Sem√°ntico

El procesamiento de documentos financieros (PDFs, reportes anuales) presenta desaf√≠os √∫nicos. El "chunking" convencional (divisi√≥n por caracteres/tokens) fragmenta tablas y estados financieros, destruyendo contexto sem√°ntico.

**Enfoque Table-Aware**: Tecnolog√≠as como **Docling** (MIT License, 2025) y **HybridChunker** permiten an√°lisis estructural que preserva tablas completas como unidades sem√°nticas indivisibles. Esto es cr√≠tico para evitar que una fila de "Revenue" quede separada de su columna de "Fiscal Year".

### 4.8 Paradigma Headless BI

**Definici√≥n**: Arquitectura donde la capa sem√°ntica act√∫a como "API of Truth" y la UI es intercambiable.

**Beneficio para esta Investigaci√≥n**: 
- **Chainlit** (frontend Python-first) sirve como consola anal√≠tica para usuarios finales con visualizaci√≥n determinista (DataFrames, SQL, Plotly).
- El mismo backend Cube Core alimenta scripts Python para ejecuci√≥n masiva de benchmarks.
- **Resultado**: Coherencia entre experimentaci√≥n acad√©mica y aplicaci√≥n pr√°ctica.

### 4.9 Arquitectura Propuesta: SDRAG

El framework **Structured Data Retrieval Augmented Generation (SDRAG)** introduce un pipeline de cuatro etapas claramente diferenciadas:

1. **Ingesta Estructural** (Docling + Dask): Procesamiento paralelo de PDFs financieros preservando estructura tabular, con chunking sem√°ntico (HybridChunker, Œ∏=0.8).

2. **Router Determinista** (n8n): Motor expl√≠cito de control de flujo que clasifica consultas en:
   - "Sem√°nticas" (m√©tricas, agregaciones) ‚Üí Cube Core
   - "Documentales" (contexto textual, definiciones) ‚Üí Weaviate
   - "H√≠bridas" (requieren datos + contexto) ‚Üí Cube Core primero, Weaviate para enriquecer
   
   La clasificaci√≥n se realiza mediante reglas determin√≠sticas y/o modelos ligeros, no mediante LLM. **Justificaci√≥n acad√©mica**: Permite auditar decisiones de enrutamiento que en sistemas LLM-driven suelen ser impl√≠citas y opacas.

3. **Ejecuci√≥n Determinista** (Cube Core + DuckDB): Capa sem√°ntica genera SQL can√≥nico, DuckDB ejecuta, resultado es trazable y reproducible.

4. **Capa de Explicaci√≥n** (Dify): Servicio LLM que recibe resultados deterministas (datos num√©ricos validados + contexto documental de Weaviate) y genera explicaciones en lenguaje natural. **Principio cr√≠tico**: Dify **solo explica**, nunca decide rutas de ejecuci√≥n ni genera SQL. Los resultados num√©ricos son inmutables en esta etapa.

5. **Visualizaci√≥n Determinista** (Chainlit): Frontend Python-first que renderiza SQL visible, DataFrames interactivos, gr√°ficos Plotly y explicaciones textuales. `cl.Step` registra trazabilidad completa de pasos de ejecuci√≥n (clasificaci√≥n ‚Üí SQL ‚Üí datos ‚Üí explicaci√≥n) mediante audit trail expl√≠cito.

**Nota sobre Weaviate y RAG Documental**: Weaviate proporciona contexto sem√°ntico para enriquecer explicaciones, no para generar respuestas num√©ricas. Se consulta para:
- Definiciones de m√©tricas ("¬øc√≥mo se calcula EBITDA?")
- Contexto de pol√≠ticas de negocio ("¬øqu√© reglas aplican a revenue recognition?")
- Referencias documentales ("¬øqu√© dice el reporte sobre este tema?")

**Cr√≠ticamente**, los valores num√©ricos **nunca provienen de Weaviate**. Los n√∫meros son exclusivamente provistos por la Capa Sem√°ntica (Cube Core), garantizando que el contexto documental act√∫e como **fuente de verdad sem√°ntica**, no como motor de c√°lculo.

---

## 5. Objetivos

### Objetivo General
Dise√±ar, implementar y evaluar una arquitectura que reduzca significativamente las alucinaciones num√©ricas en sistemas de IA Generativa financiera, utilizando una capa sem√°ntica intermedia y validaci√≥n determinista.

### Objetivos Espec√≠ficos
1.  **Implementar Capa Sem√°ntica:** Configurar **Cube Core** para definir m√©tricas financieras estandarizadas, sirviendo como "Single Source of Truth" (SSOT) para el LLM. Objetivo: garantizar que cada consulta sobre FP&A devuelve datos consistentes y auditables.
2.  **Pipeline de Ingesta Estructural:** Utilizar **Docling** para procesar documentos financieros complejos (PDFs, Excel), preservando la estructura tabular para su an√°lisis SQL con estrategia de chunking sem√°ntico. Objetivo: automatizar la carga de reportes sin p√©rdida de integridad de datos.
3.  **Validaci√≥n con Benchmarks Reales:** Evaluar la precisi√≥n de ejecuci√≥n (Execution Accuracy) utilizando datasets est√°ndar de la industria como **Spider**, **BIRD** y **FinQA**, demostrando que la arquitectura no es solo acad√©mica sino pr√°cticamente viable.
4.  **Infraestructura H√≠brida:** Demostrar la viabilidad de una arquitectura distribuida (Cloud ARM + On-Premise x86) gestionada centralmente, validando que no requiere un "data center gigante" para implementarse.
5.  **M√©tricas de √âxito Cuantificables:** Reducir significativamente las alucinaciones aritm√©ticas observadas en enfoques Text-to-SQL directos (baseline ~40% Execution Accuracy reportado en literatura), con un objetivo experimental de <5% de tasa de error medido mediante Execution Accuracy en benchmarks est√°ndar validados. **Objetivo de negocio:** proporcionar un FP&A Copilot que CFOs y analistas puedan usar con confianza, eliminando horas de retrabajo en validaci√≥n manual.
6.  **Evaluar Capa de Explicaci√≥n:** Medir el impacto de Dify en la consistencia de explicaciones, latencia adicional introducida, y calidad de las narrativas generadas, manteniendo invariabilidad de los resultados num√©ricos.

---

## 6. Metodolog√≠a

### 6.1 Dise√±o Experimental

El estudio sigue un enfoque cuantitativo comparativo con tres configuraciones:

1. **Baseline**: LLM directo (Llama 3.1 70B, Mistral Large) ejecutando Text-to-SQL sin capa sem√°ntica.
2. **RAG Tradicional**: LLM + Embeddings + Vector DB (Weaviate) generando SQL estoc√°stico.
3. **SDRAG (Propuesto)**: LLM + Cube Core + Weaviate + Dify (arquitectura determinista con explicaci√≥n controlada).

### 6.2 M√©tricas de Evaluaci√≥n

#### 6.2.1 M√©tricas Primarias
- **Execution Accuracy (EX)**: Coincidencia exacta entre resultado num√©rico esperado (ground truth del benchmark) y resultado obtenido por el sistema. Medida principal para validar reducci√≥n de alucinaciones aritm√©ticas.
- **Query Routing Accuracy**: Porcentaje de consultas correctamente clasificadas como sem√°nticas (Cube Core) vs. documentales (Weaviate). Valida efectividad de la clasificaci√≥n determin√≠stica.
- **Numerical Hallucination Rate**: Porcentaje de respuestas con error aritm√©tico detectable (discrepancia >0.01% en valores num√©ricos). M√©trica inversa a Execution Accuracy.

#### 6.2.2 M√©tricas Secundarias
- **Latency End-to-End**: Tiempo desde input del usuario hasta respuesta completa renderizada en Chainlit (p50, p95, p99). Objetivo: <2s para queries simples.
- **Reproducibilidad**: Varianza de resultados ante m√∫ltiples ejecuciones id√©nticas (mismo input, misma configuraci√≥n). M√©trica clave para validar determinismo arquitect√≥nico.
- **Traceability Completeness**: Porcentaje de consultas con SQL visible, datos auditables y pasos ejecutados documentados v√≠a `cl.Step`.
- **Explanation Consistency (Dify)**: Variabilidad de explicaciones generadas por Dify ante mismo input determinista (medida con BLEU/ROUGE entre ejecuciones m√∫ltiples). M√©trica secundaria que no afecta validez de c√°lculos.
- **LLM Latency Overhead**: Tiempo adicional introducido por Dify en el flujo (medido como: latency total - latency c√°lculo determinista). Eval√∫a costo de explicaci√≥n en lenguaje natural.

#### 6.2.3 M√©tricas de RAG Documental
- **Document RAG Activation Rate**: % de consultas que activan recuperaci√≥n documental (solo para intenciones explicativas: define, explain, how is calculated).
- **Retrieval Precision**: Relevancia de chunks recuperados vs. ground truth (cuando disponible).
- **Context Utilization**: % de contexto recuperado efectivamente utilizado en la explicaci√≥n generada.

### 6.3 Reglas de Activaci√≥n de RAG Documental

**RAG Documental (Weaviate)** se activa **exclusivamente** cuando la consulta contiene patrones sem√°nticos de tipo explicativo:
- Patrones de activaci√≥n: "c√≥mo se calcula", "definici√≥n de", "explica el concepto de", "qu√© es", "c√≥mo se determina", "qu√© dice el reporte".
- Patrones de desactivaci√≥n: consultas puramente num√©ricas, comparaciones cuantitativas, solicitudes de c√°lculo directo.

Esta regla es **implementada en n8n** mediante clasificador ligero, no mediante LLM, garantizando trazabilidad y reproducibilidad.

### 6.4 Protocolo de Validaci√≥n

Para cada benchmark, se ejecutar√°n:
1. **Fase de Conversi√≥n**: Transformaci√≥n a formato Parquet/DuckDB en DuckLake (procesamiento distribuido con Dask).
2. **Fase de Ingesta**: Indexaci√≥n de documentos no estructurados en Weaviate y definici√≥n de m√©tricas en Cube Core.
3. **Fase de Ejecuci√≥n**: 3 corridas por configuraci√≥n para medir reproducibilidad y consistencia de explicaciones.
4. **Fase de An√°lisis**: Comparaci√≥n de resultados, latencia, trazabilidad y calidad de explicaciones.

**Baseline Comparativo**: 
1. LLM directo (sin capa sem√°ntica).
2. Human performance reportado en benchmarks (cuando disponible).

---

## 7. Infraestructura T√©cnica

### 7.1 Cluster Distribuido (Red Tailscale)

La red est√° unificada mediante **Tailscale**, permitiendo una operaci√≥n transparente entre la nube y el laboratorio local.

#### 7.1.1 Nodo 1: Oracle Cloud (ARM64, Orquestador)
- **Hardware**: VM.Standard.A1.Flex - ARM Neoverse-N1 (4 cores), 24 GB RAM con ECC, 45 GB Block Volume (sistema) + 151 GB Block Volume (datos).
- **Software**: Coolify (plano de control), n8n (router de consultas), Chainlit (frontend determinista), Dask Scheduler (coordinador de procesamiento distribuido).
- **Acceso**: IP p√∫blica para https://sdrag.com.

#### 7.1.2 Nodo 2: Mac Mini (Almacenamiento + RAG Documental)
- **Hardware**: Intel i5-3210M, 16 GB RAM, 1TB HDD (MinIO/DuckLake), 480GB SSD (Weaviate).
- **Software**: MinIO (DuckLake), **Weaviate** (√∫nica base de datos vectorial), Dify (capa de explicaci√≥n LLM), Dask Worker.
- **Rol de Weaviate**: Base de datos vectorial √∫nica para RAG sobre documentos no estructurados. Almacena embeddings y texto de documentos financieros, definiciones de m√©tricas y reglas de negocio. Provee b√∫squeda h√≠brida (vectorial + BM25). **Importante**: Weaviate **nunca** devuelve valores num√©ricos como verdad. Solo provee contexto documental para enriquecer explicaciones. Los n√∫meros son exclusivamente provistos por Cube Core.
- **Rol de Dify**: Servicio exclusivo de **explicaci√≥n en lenguaje natural**. Recibe resultados deterministas de Cube Core y contexto de Weaviate, generando narrativas comprensibles. **No participa** en clasificaci√≥n de consultas, generaci√≥n de SQL ni decisiones de enrutamiento.
- **Uptime t√≠pico**: 8+ d√≠as.

#### 7.1.3 Nodo 3: Dell Vostro (C√≥mputo)
- **Hardware**: Intel i5-7200U, 32 GB RAM, 915GB SSD.
- **Software**: Ollama (inferencia de modelos locales), Cube Core (capa sem√°ntica), Dask Worker (ETL distribuido), Docling (procesamiento de documentos).
- **Rol**: Nodo principal de trabajo pesado y desarrollo local.

### 7.2 Stack de Software

- **Gesti√≥n de Dependencias**: `uv` (Astral) para entornos Python reproducibles y r√°pidos.
- **Motor Anal√≠tico**: **DuckDB** (OLAP en memoria).
- **Procesamiento Distribuido**: **Dask** (cluster de 3 nodos: Oracle Scheduler + Dell/Mac Workers).
- **Base de Datos Vectorial**: **Weaviate** (√∫nica - b√∫squeda h√≠brida vectorial + BM25).
- **Capa de Explicaci√≥n LLM**: **Dify** (Language Explanation Service - solo post-c√°lculo).
- **Interfaz Determinista**: **Chainlit** (Frontend Python-first con visualizaci√≥n de DataFrames, SQL y gr√°ficos Plotly).
- **Orquestaci√≥n**: **n8n** (Motor expl√≠cito de control de flujo determinista, permitiendo auditar decisiones de enrutamiento que en sistemas LLM-driven suelen ser impl√≠citas y opacas).
- **Capa Sem√°ntica**: **Cube Core** (Seleccionado por: caching y pre-aggregations nativas, API headless lista para consumo LLM, m√©tricas versionadas y auditables, separaci√≥n clara entre definici√≥n sem√°ntica y ejecuci√≥n; Redis para caching y coordinaci√≥n; pre-aggregations materializadas en storage compatible S3).

---

## 8. Cronograma

### ‚úÖ Semestre 1: Definici√≥n y Arquitectura (Completado)
* Revisi√≥n del estado del arte (RAG, Text-to-SQL, Semantic Layers).
* Dise√±o de la arquitectura de hardware y red (Cluster `sdrag.com`).
* Selecci√≥n del stack tecnol√≥gico (Cube, Docling, Coolify).

### üöß Semestre 2: Implementaci√≥n del Core (En Progreso)
* Despliegue de **cluster Dask distribuido** (Scheduler en Oracle Cloud, Workers en Dell + Mac Mini).
* Despliegue y configuraci√≥n de **Cube Core** y **MinIO** (DuckLake).
* Despliegue de **Dify** en Mac Mini como capa de explicaci√≥n LLM (post-c√°lculo).
* Despliegue de **Weaviate** como √∫nica base de datos vectorial para RAG documental.
* Desarrollo del pipeline de ingesta ETL con **Docling** y **Dask** (procesamiento paralelo de benchmarks).
* Conversi√≥n completa de Benchmarks (**Spider**, **BIRD**, **FinQA**) a formato Parquet/DuckDB en DuckLake (~65-80 GB totales) usando procesamiento distribuido (speedup estimado: 4x vs. secuencial).
* Implementaci√≥n de estrategia de chunking sem√°ntico (HybridChunker) con Œ∏=0.8 para preservar estructura de tablas.
* Pruebas iniciales de conexi√≥n LLM -> Capa Sem√°ntica.
* **Integraci√≥n de Dify**: Implementaci√≥n de flujo n8n ‚Üí Dify ‚Üí n8n para generaci√≥n controlada de explicaciones en lenguaje natural.
* **M√©tricas de Performance**: Reducci√≥n de ~30 horas ‚Üí ~10 horas por ciclo completo de experimentaci√≥n (conversi√≥n + procesamiento + embeddings).

### üìÖ Semestre 3: Orquestaci√≥n y Refinamiento
* Implementaci√≥n de flujos de routing en **n8n** (clasificaci√≥n sem√°ntica vs. documental).
* Desarrollo de l√≥gica de enrutamiento para consultas h√≠bridas.
* Refinamiento de la interfaz **Chainlit** con visualizaciones deterministas (DataFrames, SQL, Plotly).
* Optimizaci√≥n de latencia end-to-end (objetivo: <2s para queries simples).
* Integraci√≥n de `cl.Step` para trazabilidad completa de ejecuci√≥n.
* **Evaluaci√≥n de Dify**: Medici√≥n de consistencia de explicaciones, latencia overhead y comparaci√≥n entre diferentes modelos LLM.

### üìÖ Semestre 4: Evaluaci√≥n y Defensa
* Ejecuci√≥n de benchmarks comparativos (LLM solo vs. LLM + Cube vs. SDRAG completo).
* Medici√≥n de latencia, precisi√≥n y tasa de alucinaci√≥n.
* An√°lisis de trade-offs entre consistencia de explicaciones y variabilidad estoc√°stica del LLM.
* Redacci√≥n de tesis y defensa final.

---

## 9. Datasets de Validaci√≥n

Para asegurar el rigor cient√≠fico, el sistema ser√° evaluado utilizando:

### Text-to-SQL Benchmarks
* **Spider (2018):** 10,181 pares pregunta-SQL, 200 bases de datos (~5 GB). Dataset de referencia para Text-to-SQL con baseline establecido (~40% Execution Accuracy sin capa sem√°ntica).
* **BIRD (2023):** 12,751 ejemplos, 95 bases de datos (33.4 GB). Dataset realista con datos "sucios" y conocimiento externo, representando escenarios corporativos complejos.
* **WikiSQL (2017):** 80,654 ejemplos, 24,241 tablas (~3 GB). Queries SQL simples (SELECT + WHERE), √∫til para validar capacidades b√°sicas de la capa sem√°ntica.

### Financial Reasoning Benchmarks
* **FinQA (2021):** Dataset de razonamiento num√©rico financiero (~1 GB). Validaci√≥n espec√≠fica de operaciones aritm√©ticas sobre reportes financieros (P&L, Balance Sheet).
* **TAT-QA (2021):** 16,552 preguntas sobre 2,757 reportes financieros (~2 GB). QA h√≠brido (tablas + texto) requiriendo numerical reasoning (suma, resta, comparaci√≥n). Human performance: 84.1% F1.
* **FinanceBench (2023):** 150 ejemplos human-annotated con ground truth (~500 MB). Revela que GPT-4-Turbo con RAG falla 81% de preguntas financieras, justificando necesidad de capa sem√°ntica.
* **ConvFinQA (2022):** QA conversacional financiero requiriendo c√°lculos multi-hop (~800 MB). Eval√∫a capacidad de mantener contexto en di√°logos financieros.

### Table Reasoning Benchmarks
* **WikiTableQuestions (2015):** Preguntas complejas sobre tablas de Wikipedia (~1 GB). Eval√∫a comprensi√≥n de estructuras tabulares.
* **SQA (Sequential QA, 2017):** 6,066 secuencias de preguntas (~500 MB). Valida capacidad de razonamiento multi-turno sobre tablas.

**Almacenamiento Total Estimado:** ~80-95 GB (Parquet + embeddings) alojados en DuckLake (MinIO en Mac Mini 1TB).

---

## 10. Filosof√≠a del Proyecto: "Business Outcomes First"

Esta tesis rechaza el enfoque tradicional acad√©mico que separa la "viabilidad t√©cnica" del "impacto real". Cada componente debe justificar su existencia respondiendo: **¬øQu√© problema de negocio resuelve esto?**

Los departamentos de FP&A corporativos sufren de:
- **Errores aritm√©ticos** recurrentes que requieren validaci√≥n manual
- **Inconsistencias** en definiciones de m√©tricas entre reportes
- **Retrabajo cr√≥nico** en cada ciclo de cierre contable
- **Desconfianza ejecutiva** en los n√∫meros ("¬øeste n√∫mero es correcto?")

Esta tesis propone una arquitectura que resuelve estos problemas mediante una **Capa Sem√°ntica como √Årbitro Determinista**. No es un "experimento de laboratorio bonito" ‚Äî es una herramienta que FP&A departments pueden usar hoy para mejorar su eficiencia y confiabilidad.

**Mandato de la investigaci√≥n:** "¬øCu√°l es la arquitectura m√≠nima que le permite a un CFO confiar en los n√∫meros?" Una vez respondida, todo lo dem√°s es implementaci√≥n.

---

## 11. Limitaciones del Sistema

Esta implementaci√≥n prioriza rigor experimental y reproducibilidad sobre escalabilidad industrial completa:

- **No implementa alta disponibilidad (HA)** ni replicaci√≥n multi-nodo de storage para producci√≥n 24/7.
- **No aborda escenarios multi-tenant** ni control de costos a gran escala con cientos de usuarios concurrentes.
- **El enfoque se centra en precisi√≥n y trazabilidad**, no en auto-scaling din√°mico de inferencia o elasticidad cloud.
- **Infraestructura h√≠brida limitada** a recursos disponibles (3 nodos f√≠sicos), sin redundancia geogr√°fica.
- **Weaviate no genera n√∫meros**: Solo provee contexto documental (texto, referencias, definiciones). Los n√∫meros son exclusivamente provistos por Cube Core.
- **GraphRAG limitado a 1-2 saltos**: Razonamiento multi-hop complejo queda fuera del alcance, priorizando simplicidad verificable.
- **Dify es una capa controlada**: Aunque introduce variabilidad estoc√°stica en las explicaciones (inherente a los LLMs), esta variabilidad **no afecta los resultados num√©ricos** que son inmutables al llegar a Dify. La consistencia de explicaciones se evaluar√° como m√©trica secundaria, pero no compromete la validez de los c√°lculos.

Estas limitaciones **no invalidan los resultados**, ya que el objetivo de la investigaci√≥n es evaluar la reducci√≥n de alucinaciones mediante dise√±o arquitect√≥nico, no construir un sistema enterprise completo. La arquitectura propuesta es **escalable conceptualmente** y puede adaptarse a entornos de producci√≥n con recursos adicionales.

---

## 12. Bibliograf√≠a (Selecci√≥n)

* Chen, M., et al. (2025). *Reliable Text-to-SQL with Adaptive Abstention*. arXiv.
* Finegan-Dollak, C., et al. (2018). *Improving Text-to-SQL Evaluation Methodology*. ACL.
* Gong, S., et al. (2025). *SQLens: An End-to-End Framework for Error Detection and Correction in Text-to-SQL*. arXiv.
* Guo, W., et al. (2025). *SQLForge: Synthesizing Reliable and Diverse Data to Enhance Text-to-SQL Reasoning in LLMs*. arXiv.
* Li, Z., et al. (2023). *FinanceBench: A Benchmark for Evaluating LLMs in Financial Question Answering*. arXiv.
* OpenAI. (2023). *GPT-4 Technical Report*.
* Taori, R., et al. (2023). *Alpaca: A Strong, Replicable Instruction-Following Model*. Stanford CRFM.
* Wei, J., et al. (2023). *Chain-of-Thought Prompting Elicits Reasoning in Large Language Models*. NeurIPS.
* Yao, S., et al. (2023). *ReAct: Synergizing Reasoning and Acting in Language Models*. ICLR.

---

*Documento generado el 19 de enero de 2026. Propiedad intelectual del autor, H√©ctor Gabriel S√°nchez P√©rez.*
