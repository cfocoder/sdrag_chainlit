## UNIVERSIDAD DE GUADALAJARA

## CENTRO UNIVERSITARIO DE CIENCIAS ECON√ìMICO ADMINISTRATIVAS

## COORDINACI√ìN DE POSGRADO

## MAESTR√çA EN CIENCIA DE LOS DATOS

<!-- image -->

Protocolo de Investigaci√≥n
Arquitectura RAG H√≠brida con Capa Sem√°ntica Determinista (SDRAG) para Reducir Alucinaciones Aritm√©ticas en Anal√≠tica Financiera (FP&A)

## P R E S E N T A

## HECTOR GABRIEL SANCHEZ PEREZ

Enero 19, 2026
www.cfocoder.com
hector@sanchezmx.com
+52 (33) 1286-6700

<!-- image -->

<!-- image -->

---

## 1. T√≠tulo

**Arquitectura RAG H√≠brida con Capa Sem√°ntica Determinista para Reducir Alucinaciones Aritm√©ticas en Sistemas de IA Generativa aplicados a Anal√≠tica Financiera (FP&A)**

---

## 2. Planteamiento del Problema

Los Grandes Modelos de Lenguaje (LLMs) han demostrado capacidades excepcionales en tareas de procesamiento de lenguaje natural, pero presentan limitaciones cr√≠ticas al interactuar con datos estructurados, especialmente en contextos financieros donde la precisi√≥n num√©rica es imperativa.

### 2.1 Descripci√≥n del Problema

La integraci√≥n de LLMs en procesos de Planificaci√≥n y An√°lisis Financiero (FP&A) enfrenta desaf√≠os fundamentales que limitan su adopci√≥n en entornos corporativos:

1. **Alucinaciones Aritm√©ticas**: Los LLMs, por su naturaleza estoc√°stica, generan c√°lculos incorrectos y resultados financieros inexactos. La literatura cient√≠fica documenta tasas de error del ~40% en tareas Text-to-SQL sin asistencia estructural (Spider Benchmark baseline).

2. **Degradaci√≥n en Text-to-SQL Directo**: Estudios recientes (FinanceBench 2023) reportan tasas de falla superiores al 80% en preguntas financieras que requieren precisi√≥n num√©rica con GPT-4-Turbo y RAG tradicional, evidenciando la insuficiencia de los enfoques vectoriales puros.

3. **Opacidad en Decisiones de Ejecuci√≥n**: Los sistemas actuales (OpenWebUI, copilots gen√©ricos) delegan en el LLM la decisi√≥n de **qu√© ejecutar y c√≥mo**, generando rutas de ejecuci√≥n impl√≠citas y no auditables.

4. **Falta de Trazabilidad**: La ausencia de registro expl√≠cito de pasos de ejecuci√≥n (SQL generado, datos recuperados, c√°lculos intermedios) impide la validaci√≥n forense necesaria en auditor√≠as financieras.

### 2.2 Pregunta de Investigaci√≥n

¬øPuede una arquitectura de **ejecuci√≥n determinista con explicaci√≥n asistida por lenguaje** (SDRAG) reducir significativamente las alucinaciones aritm√©ticas en sistemas de IA generativa aplicados a anal√≠tica financiera, comparada con enfoques Text-to-SQL directos y RAG tradicionales?

**Pregunta Secundaria**: ¬øEs el paradigma Headless BI (capa sem√°ntica como API + UI intercambiable) una arquitectura viable para garantizar reproducibilidad en experimentos acad√©micos y aplicabilidad en producci√≥n simult√°neamente?

### 2.3 Delimitaci√≥n del Alcance

- **Temporal**: Desarrollo durante 4 semestres acad√©micos (2025-2027).
- **Espacial**: Infraestructura distribuida h√≠brida (Oracle Cloud ARM64 + laboratorio local x86 en Guadalajara, M√©xico).
- **T√©cnica**: Framework SDRAG con validaci√≥n mediante benchmarks est√°ndar (Spider, BIRD, FinQA, TAT-QA, FinanceBench).
- **Dominio**: Anal√≠tica financiera (FP&A) como caso de estudio, con arquitectura agn√≥stica al dominio para permitir generalizaci√≥n.
- **Limitaciones Expl√≠citas**:
  - No implementa alta disponibilidad (HA) ni replicaci√≥n multi-nodo.
  - Infraestructura limitada a 3 nodos f√≠sicos disponibles.
  - Prioriza precisi√≥n y trazabilidad sobre escalabilidad industrial completa.

---

## 3. Justificaci√≥n

### 3.1 Relevancia Acad√©mica

Este proyecto contribuye al campo emergente de **arquitecturas de IA con ejecuci√≥n determin√≠stica** al proponer un modelo que combina:

- **Generaci√≥n flexible** (LLMs) para interpretaci√≥n de lenguaje natural y generaci√≥n de explicaciones post-c√°lculo.
- **Ejecuci√≥n determin√≠stica** (Capa Sem√°ntica v√≠a Cube Core) para garantizar precisi√≥n num√©rica y reproducibilidad.
- **Clasificaci√≥n expl√≠cita** (n8n con reglas determin√≠sticas) para control de flujo auditable.

**Nota conceptual**: El determinismo se aplica a nivel de **ejecuci√≥n de c√°lculos**, no a la generaci√≥n ling√º√≠stica del LLM. El modelo estoc√°stico solo genera explicaciones sobre resultados ya validados.

**Vac√≠o en la Literatura**: La investigaci√≥n actual en RAG se enfoca en recuperaci√≥n de documentos no estructurados. Existe escasa literatura sobre arquitecturas de producci√≥n para LLMs en contextos de alta sensibilidad num√©rica (finanzas, salud, infraestructura cr√≠tica) que garanticen trazabilidad completa.

**Diferenciaci√≥n vs. Estado del Arte**:

| Dimensi√≥n | RAG Tradicional | SDRAG (Propuesto) |
|-----------|-----------------|-------------------|
| **Generaci√≥n de n√∫meros** | LLM genera valores | ‚ùå Prohibido - Solo capa sem√°ntica |
| **SQL** | Generado por LLM (estoc√°stico) | ‚úÖ Determinista v√≠a Cube Core |
| **Ruta de ejecuci√≥n** | Decidida por LLM | ‚úÖ Reglas + Clasificador ligero (n8n) |
| **Explicaci√≥n** | LLM genera explicaci√≥n + datos | ‚úÖ Dify solo explica datos validados |
| **Contexto documental** | M√∫ltiples vector stores | ‚úÖ Weaviate √∫nica (simplificaci√≥n deliberada) |
| **Navegaci√≥n documental** | Chunking tradicional | ‚úÖ PageIndex (indexaci√≥n jer√°rquica) |
| **Trazabilidad** | Parcial (prompt ‚Üí respuesta) | ‚úÖ Completa (SQL + datos + pasos) |
| **Reproducibilidad** | Baja (temperatura ‚â† 0) | ‚úÖ Alta (mismo input ‚Üí mismo output) |
| **Riesgo de alucinaci√≥n aritm√©tica** | Alto (~40% error) | ‚úÖ Bajo por dise√±o arquitect√≥nico |

**Nota sobre Dify**: En SDRAG, Dify act√∫a exclusivamente como **capa de explicaci√≥n post-c√°lculo**. Recibe resultados ya validados por Cube Core y genera explicaciones en lenguaje natural sin modificar datos ni participar en decisiones de enrutamiento. Esta separaci√≥n estricta es clave para mantener el determinismo arquitect√≥nico.

### 3.2 Relevancia Profesional

El investigador posee 30+ a√±os de experiencia en anal√≠tica financiera corporativa (KPMG, Motorola, HP, OpenText, Weave Communications), proporcionando:

- **Conocimiento del dominio** para validar casos de uso realistas de FP&A.
- **Acceso a procesos** para fundamentar requisitos t√©cnicos (cierres contables, an√°lisis de varianza, forecasting).
- **Capacidad de implementaci√≥n** en infraestructura auto-hospedada con presupuesto acad√©mico (~$0-150 USD).

### 3.3 Impacto Esperado

**Sector Acad√©mico**:
- Establecimiento de metodolog√≠a reproducible para evaluaci√≥n de LLMs en datos estructurados.
- Protocolo de m√©tricas expl√≠cito (Execution Accuracy, Query Routing Accuracy, Numerical Hallucination Rate, Traceability Completeness, Explanation Consistency) que otros investigadores pueden replicar.
- Contribuci√≥n al estado del arte en arquitecturas RAG h√≠bridas con navegaci√≥n documental jer√°rquica.

**Sector Empresarial**:
- Reducci√≥n de costos de infraestructura (arquitectura auto-hospedada vs. servicios cloud propietarios).
- Democratizaci√≥n de anal√≠tica avanzada para PyMEs mediante software open-source.
- **Valor operativo verificable**: Eliminaci√≥n de errores aritm√©ticos, consistencia en c√°lculos, trazabilidad completa, reducci√≥n de retrabajo en validaci√≥n manual.

---

## 4. Antecedentes / Marco Te√≥rico

### 4.1 Estado del Arte: Text-to-SQL

Los sistemas Text-to-SQL permiten consultar bases de datos usando lenguaje natural. Los enfoques tradicionales se clasifican en:

**Modelos Directos (LLM ‚Üí SQL)**:
- Ventajas: Simplicidad arquitectural, baja latencia.
- Limitaciones: Tasa de error ~40% (Spider), incapacidad de manejar esquemas complejos (BIRD 33.4 GB con datos "sucios").

**RAG Tradicional (LLM + Vectores)**:
- Ventajas: Contexto extendido, recuperaci√≥n de ejemplos similares.
- Limitaciones: FinanceBench reporta 81% de falla en c√°lculos financieros, evidenciando que embeddings solos no garantizan precisi√≥n aritm√©tica.

### 4.2 Capas Sem√°nticas (Semantic Layers): El √Årbitro Determinista

**Definici√≥n**: Una capa sem√°ntica abstrae la complejidad de bases de datos, exponiendo m√©tricas de negocio estandarizadas mediante APIs. Act√∫a como "Single Source of Truth" (SSOT).

**Tecnolog√≠as Principales**:
- **Cube Core** (Open Source): Define m√©tricas como c√≥digo (YAML/JavaScript), genera SQL optimizado, provee caching y pre-aggregations nativas.
- **dbt Semantic Layer**: Enfoque declarativo con materializaci√≥n incremental.
- **MetricFlow** (dbt Labs): Define m√©tricas como objetos de primera clase.

**Ventaja para LLMs**: El LLM consume un cat√°logo simplificado de m√©tricas (e.g., "Revenue", "COGS", "EBITDA") en lugar de tablas crudas, reduciendo la superficie de error.

**Justificaci√≥n de Cube Core**:
1. Caching y pre-aggregations nativas (Redis).
2. API headless lista para consumo LLM (REST/GraphQL).
3. M√©tricas versionadas y auditables (Git-based).
4. Separaci√≥n clara entre definici√≥n sem√°ntica y ejecuci√≥n SQL.

### 4.3 Plataformas LLM de Producci√≥n: Dify como Capa de Explicaci√≥n

**Dify** es una plataforma open-source para desarrollo de aplicaciones LLM que provee:
- Gesti√≥n de prompts versionados
- Orquestaci√≥n de flujos LLM
- Observabilidad y m√©tricas de inferencia
- Soporte multi-modelo (OpenAI, Anthropic, modelos locales)

**Rol en SDRAG**: Dify se utiliza exclusivamente como **Language Explanation Service**. Su funci√≥n es transformar resultados ya calculados y validados por componentes deterministas (Cube Core, DuckDB) en explicaciones comprensibles para el usuario final.

**Principio Central**: Dify **no participa en**:
- Toma de decisiones o clasificaci√≥n de consultas (responsabilidad de n8n)
- Generaci√≥n de SQL o queries (responsabilidad de Cube Core)
- Selecci√≥n de rutas de ejecuci√≥n (responsabilidad de n8n)
- Validaci√≥n de resultados num√©ricos (responsabilidad de Cube Core + DuckDB)

Esta separaci√≥n garantiza reproducibilidad, auditabilidad y alineaci√≥n con los principios de SDRAG.

### 4.4 Weaviate: Base de Datos Vectorial √önica para RAG Documental

**Weaviate** es una base de datos vectorial open-source que combina b√∫squeda por similitud sem√°ntica (vectorial) con b√∫squeda por palabras clave (BM25). En SDRAG, Weaviate act√∫a como la **√∫nica base de datos vectorial** del proyecto, responsable del RAG sobre documentos no estructurados.

#### Justificaci√≥n de Weaviate como √önica Base Vectorial

La decisi√≥n de utilizar una √∫nica base de datos vectorial responde a principios de **reducci√≥n de complejidad innecesaria** alineados con los objetivos de precisi√≥n, trazabilidad y control del razonamiento:

1. **Simplicidad arquitect√≥nica**: Un √∫nico punto de acceso para contexto documental elimina la necesidad de l√≥gica de routing entre m√∫ltiples vector stores.

2. **Trazabilidad mejorada**: Toda consulta documental se resuelve en un √∫nico sistema, facilitando auditor√≠a y debugging.

3. **Mantenimiento reducido**: Un solo sistema vectorial implica menor overhead operativo (backups, actualizaciones, monitoreo).

4. **Consistencia de √≠ndices**: Sin riesgo de desincronizaci√≥n entre m√∫ltiples bases de datos vectoriales.

5. **Recursos limitados**: La infraestructura acad√©mica (3 nodos) se beneficia de la consolidaci√≥n de servicios.

#### Rol de Weaviate en SDRAG

Weaviate **S√ç es responsable de**:
- Almacenar y recuperar embeddings de documentos no estructurados (PDFs, Markdown, documentaci√≥n t√©cnica).
- Proveer b√∫squeda h√≠brida (vectorial + BM25) para maximizar relevancia de recuperaci√≥n.
- Almacenar definiciones de m√©tricas, reglas de negocio y documentaci√≥n de Cube Core.
- Soportar relaciones impl√≠citas entre objetos (GraphRAG ligero) mediante referencias cruzadas entre clases.
- **Integraci√≥n con PageIndex**: Almacenar referencias a nodos de √≠ndices jer√°rquicos generados por PageIndex, permitiendo filtrado preciso por `page_index` durante la recuperaci√≥n.

Weaviate **NO participa en**:
- Generaci√≥n de valores num√©ricos (responsabilidad exclusiva de Cube Core).
- C√°lculos aritm√©ticos o agregaciones.
- Ejecuci√≥n de SQL o consultas anal√≠ticas.
- Toma de decisiones de enrutamiento (responsabilidad de n8n).
- Navegaci√≥n estructural de documentos jer√°rquicos (responsabilidad de PageIndex).

**Principio Cr√≠tico**: Los valores num√©ricos **nunca provienen de Weaviate**. Weaviate proporciona contexto sem√°ntico (definiciones, ejemplos, documentaci√≥n), no resultados de c√°lculo. En caso de conflicto entre contexto documental (Weaviate) y resultados estructurados (Cube Core), **siempre prevalece Cube Core**.

**Objetivo del RAG Documental**: El sistema RAG documental **no produce respuestas finales num√©ricas**, sino que **identifica, relaciona y cita correctamente** los fragmentos legales/documentales relevantes que soportan una decisi√≥n. La interpretaci√≥n final y responsabilidad profesional permanece en el usuario experto (CPA, abogado).

#### GraphRAG Impl√≠cito en Weaviate

Weaviate permite modelar relaciones entre objetos mediante referencias cruzadas entre clases, habilitando un **GraphRAG ligero** sin necesidad de una base de datos de grafos dedicada:

**Clases en Weaviate**:
- `Document`: Documentos fuente (PDFs, reportes, papers).
- `Chunk`: Fragmentos sem√°nticos extra√≠dos de documentos.
- `MetricDefinition`: Definiciones de m√©tricas de Cube Core.
- `BusinessRule`: Reglas de c√°lculo y pol√≠ticas de negocio.
- `PageIndexReference`: **[NUEVO]** Referencias a nodos de √≠ndices jer√°rquicos de PageIndex.

**Relaciones (Cross-references)**:
- `Chunk` ‚Üí `belongsTo` ‚Üí `Document`
- `MetricDefinition` ‚Üí `referencedIn` ‚Üí `Document`
- `Chunk` ‚Üí `defines` ‚Üí `MetricDefinition`
- `BusinessRule` ‚Üí `appliesTo` ‚Üí `MetricDefinition`
- `PageIndexReference` ‚Üí `belongsTo` ‚Üí `Document`
- `Chunk` ‚Üí `referencedBy` ‚Üí `PageIndexReference`

Esta estructura permite consultas de tipo:
- "¬øQu√© documentos definen la m√©trica EBITDA?"
- "¬øQu√© reglas de negocio aplican a Revenue Recognition?"
- "¬øEn qu√© secci√≥n del reporte se menciona esta m√©trica?"
- "¬øQu√© nodos de PageIndex contienen informaci√≥n sobre art√≠culos fiscales?"

**Limitaci√≥n deliberada**: El GraphRAG en Weaviate se limita a **1-2 saltos** de profundidad. Consultas de razonamiento multi-hop complejo quedan fuera del alcance de esta investigaci√≥n, priorizando la **simplicidad verificable** sobre la sofisticaci√≥n arquitect√≥nica.

### 4.5 RAG sobre Documentos No Estructurados: Alcance y Limitaciones

El uso de RAG en SDRAG se limita **exclusivamente** a documentos no estructurados y cumple un rol **estrictamente auxiliar**:

#### Tipos de Documentos Indexados en Weaviate

| Tipo de Documento | Prop√≥sito en SDRAG | Ejemplo |
|-------------------|-------------------|---------|
| PDFs financieros | Contexto explicativo, referencias | Annual Report 2024.pdf |
| Markdown / Documentaci√≥n | Definiciones, metodolog√≠as | metric_definitions.md |
| Documentaci√≥n t√©cnica | Contexto de implementaci√≥n | cube_model_docs.md |
| Reglas de negocio | Pol√≠ticas de c√°lculo | revenue_recognition_policy.md |
| Papers de investigaci√≥n | Marco te√≥rico, referencias | FinanceBench_2023.pdf |
| **Documentos legales largos** | **Leyes, contratos, actas corporativas** | **Ley_del_ISR.pdf** |

#### Consultas que S√ç se Resuelven con RAG (Weaviate)

- "¬øC√≥mo se define el margen bruto seg√∫n las pol√≠ticas de la empresa?"
- "¬øQu√© dice el reporte anual sobre revenue recognition?"
- "¬øCu√°l es la metodolog√≠a de c√°lculo de EBITDA documentada?"
- "¬øQu√© secciones del reporte mencionan amortizaci√≥n?"

#### Consultas que NO se Resuelven con RAG

- ‚ùå "¬øCu√°l fue el EBITDA de Q3 2024?" ‚Üí **Cube Core**
- ‚ùå "¬øCu√°nto creci√≥ el revenue YoY?" ‚Üí **Cube Core**
- ‚ùå "Calcula el margen operativo" ‚Üí **Cube Core**
- ‚ùå "¬øCu√°l es el total de gastos?" ‚Üí **Cube Core**

**Regla fundamental**: Toda consulta que requiera un **valor num√©rico como respuesta** se resuelve exclusivamente mediante Cube Core. Weaviate proporciona **contexto para explicar** esos valores, nunca los valores mismos.

### 4.6 Benchmarks de Validaci√≥n

**Text-to-SQL Benchmarks**:
- **Spider (2018)**: 10,181 pares pregunta-SQL, 200 bases de datos (~5 GB). Baseline: ~40% Execution Accuracy sin capa sem√°ntica.
- **BIRD (2023)**: 12,751 ejemplos, 95 bases de datos (33.4 GB). Dataset realista con datos "sucios" y conocimiento externo.
- **WikiSQL (2017)**: 80,654 ejemplos, 24,241 tablas (~3 GB). Queries SQL simples (SELECT + WHERE).

**Financial Reasoning Benchmarks**:
- **FinQA (2021)**: 8,281 preguntas sobre reportes financieros (~1 GB), requiriendo operaciones aritm√©ticas multi-paso.
- **TAT-QA (2021)**: 16,552 preguntas sobre 2,757 reportes (~2 GB). QA h√≠brido (tablas + texto). Human performance: 84.1% F1.
- **FinanceBench (2023)**: 150 ejemplos human-annotated (~500 MB). Revela que GPT-4-Turbo con RAG falla 81% de preguntas financieras.
- **ConvFinQA (2022)**: QA conversacional financiero (~800 MB), eval√∫a razonamiento multi-hop.

**Table Reasoning Benchmarks**:
- **WikiTableQuestions (2015)**: Preguntas complejas sobre tablas (~1 GB).
- **SQA (2017)**: 6,066 secuencias de preguntas (~500 MB).

**Almacenamiento Total Estimado**: ~80-95 GB (Parquet + embeddings) en DuckLake.

### 4.7 Procesamiento de Documentos Financieros: Chunking Sem√°ntico

El procesamiento de documentos financieros (PDFs, reportes anuales) presenta desaf√≠os √∫nicos. El "chunking" convencional (divisi√≥n por caracteres/tokens) fragmenta tablas y estados financieros, destruyendo contexto sem√°ntico.

**Enfoque Table-Aware**: Tecnolog√≠as como **Docling** (MIT License, 2025) y **HybridChunker** permiten an√°lisis estructural que preserva tablas completas como unidades sem√°nticas indivisibles. Esto es cr√≠tico para evitar que una fila de "Revenue" quede separada de su columna de "Fiscal Year".

### 4.8 PageIndex: Indexaci√≥n Jer√°rquica para RAG Documental Avanzado

**PageIndex** es un framework de RAG **vectorless** (sin dependencia exclusiva de bases de datos vectoriales) basado en razonamiento que transforma documentos largos y complejos en **√≠ndices jer√°rquicos en forma de √°rbol**. A diferencia de los sistemas RAG tradicionales que dependen de b√∫squeda de similitud sem√°ntica, PageIndex permite que los LLMs **razonen sobre la estructura del documento** para realizar retrieval contextualizado y agentic.

#### Principio Central

**"Similarity ‚â† Relevance"**: Lo que se necesita es razonamiento sobre estructura, no solo coincidencia de embeddings. PageIndex se inspira en algoritmos de b√∫squeda en √°rbol (como los de AlphaGo) pero aplicados a navegaci√≥n documental.

#### Capacidades Principales

1. **Generaci√≥n de √çndices Jer√°rquicos**
   - Crea una "tabla de contenidos" optimizada para LLMs a partir de PDFs y Markdown.
   - Preserva la jerarqu√≠a l√≥gica del documento (t√≠tulos, secciones, subsecciones).
   - Cada nodo contiene:
     - `title`: Nombre descriptivo
     - `node_id`: Identificador √∫nico
     - `page_index` / `start_index` - `end_index`: Referencias de p√°gina exactas
     - `summary`: Resumen generado (opcional)
     - `nodes`: Subnodos anidados (estructura recursiva)

2. **Retrieval Agentic (Tree Search)**
   - Razonamiento multi-step iterativo sobre la estructura del √°rbol.
   - Navegaci√≥n como humanos (ej: "ver Ap√©ndice G", "revisar Cap√≠tulo 5").
   - Traceable y explicable: cada decisi√≥n es razonada, no opaca como b√∫squeda vectorial.

3. **Preservaci√≥n de Estructura Multi-p√°gina**
   - PageIndex OCR utiliza vision-language models con contexto largo.
   - Trata el documento entero como unidad cohesiva.
   - Preserva referencias cruzadas ("ver Tabla 5.3", "Ap√©ndice G").
   - Mantiene integridad de tablas y layouts complejos.

#### Tipos de Documentos Soportados

| Formato | Soporte | Caracter√≠sticas |
|---------|---------|-----------------|
| **PDF (nativo)** | Excelente | Mejor con PageIndex OCR para PDFs escaneados |
| **PDF (digitales)** | Excelente | An√°lisis de estructura directa |
| **Markdown** | Soportado | Requiere jerarqu√≠a correcta con # ## ### |
| **HTML** | No directo | Convertir a Markdown con PageIndex OCR |

**Casos de uso ideales**:
- Reportes financieros (10K, 20-F, earnings reports)
- Documentos regulatorios (SEC filings, compliance)
- **Leyes completas (Ley del ISR, c√≥digos fiscales)**
- **Contratos y actas corporativas**
- Documentaci√≥n t√©cnica larga
- Cualquier documento > context window del LLM

#### Estrategia de Chunking Natural

PageIndex **NO usa chunking artificial**. En su lugar:
- Identifica **l√≠mites naturales** basados en estructura (t√≠tulos, secciones).
- Cada nodo respeta l√≠mites sem√°nticos del documento.
- Par√°metros configurables:
  - `max-pages-per-node`: M√°ximo de p√°ginas por nodo (default: 10)
  - `max-tokens-per-node`: M√°ximo de tokens por nodo (default: 20000)
  - `toc-check-pages`: P√°ginas a escanear para tabla de contenidos (default: 20)

#### Integraci√≥n con Weaviate

PageIndex **complementa** a Weaviate, no lo reemplaza:

**Principio de Integraci√≥n**: PageIndex no elimina la b√∫squeda sem√°ntica; la **precede y la restringe** mediante estructura jer√°rquica. La b√∫squeda vectorial permanece como mecanismo de recuperaci√≥n, pero opera sobre un espacio reducido y estructurado.

1. **PageIndex act√∫a primero**: Identifica secciones relevantes mediante razonamiento sobre la estructura jer√°rquica del documento.

2. **Weaviate act√∫a despu√©s**: Filtra b√∫squeda vectorial por los `page_index` identificados por PageIndex, recuperando chunks espec√≠ficos con mayor precisi√≥n.

3. **Clase PageIndexReference en Weaviate**: Almacena referencias a nodos de PageIndex con metadata:
   ```
   {
     node_id: "0006",
     title: "Financial Stability",
     summary: "The Federal Reserve maintains...",
     start_page: 21,
     end_page: 28,
     parent_node_id: "0002",
     belongsTo: Document
   }
   ```

4. **Flujo combinado**:
   ```
   PageIndex Tree Search
         ‚Üì
   Identifica nodos relevantes (node_id, page_index, summary)
         ‚Üì
   Weaviate busca chunks dentro de page_index espec√≠ficos
         ‚Üì
   Contexto curado para LLM
   ```

#### Ventajas sobre RAG Vectorial Tradicional

| Caracter√≠stica | PageIndex | Vector RAG Tradicional |
|---|---|---|
| **Preserva jerarqu√≠a** | ‚úÖ | ‚ùå (chunking fragmenta) |
| **Razonamiento multi-step** | ‚úÖ | ‚ùå (solo similarity) |
| **Referencias cruzadas** | ‚úÖ (tree search) | ‚ùå |
| **Determinismo estructural** | ‚úÖ | ‚ùå (opaco) |
| **Context fragmentation** | ‚ùå (nodos coherentes) | ‚úÖ (problema cr√≠tico) |
| **Explicabilidad** | ‚úÖ (razonada) | ‚ùå (caja negra) |

#### Resultados de Benchmarks

- **Mafin 2.5** (RAG reasoning-based con PageIndex para finanzas): **98.7% accuracy en FinanceBench**
- Significativamente superior a sistemas RAG vectoriales tradicionales
- Casos de uso: an√°lisis de SEC filings, earnings reports, documentos regulatorios

#### Despliegue en SDRAG

**Opci√≥n recomendada**: MCP Server Local
**Estrategia de Despliegue**:
- **Implementaci√≥n**: MCP Server Local auto-hospedado
  - Comando: `npx -y @pageindex/mcp`
  - Configuraci√≥n MCP: `{"mcpServers": {"pageindex": {"command": "npx", "args": ["-y", "@pageindex/mcp"]}}}`
  - Requiere: Node.js ‚â•18.0.0
  - Privacidad: Documentos permanecen completamente locales
  - Infraestructura cero, replicabilidad garantizada
- **Alternativa (si necesario Semestre 3+)**: Auto-hospedado como MCP server
  - Entorno: Dell Vostro (32 GB RAM disponibles)
  - Cambio transparente: reemplazar MCP endpoint sin modificar l√≥gica de aplicaci√≥n

### 4.9 Flujo H√≠brido PageIndex + Weaviate

El framework **Structured Data Retrieval Augmented Generation (SDRAG)** introduce un pipeline de cuatro etapas claramente diferenciadas, ahora con **PageIndex** como capa de navegaci√≥n documental avanzada:

1. **Ingesta Estructural** (Docling + Dask + PageIndex):
   - Procesamiento paralelo de PDFs financieros preservando estructura tabular.
   - Chunking sem√°ntico (HybridChunker, Œ∏=0.8).
   - **[NUEVO]** Generaci√≥n de √≠ndices jer√°rquicos con PageIndex para documentos largos (>50 p√°ginas).

2. **Router Determinista** (n8n):
   - Motor expl√≠cito de control de flujo que clasifica consultas en:
     - "Sem√°nticas" (m√©tricas, agregaciones) ‚Üí **Cube Core**
     - "Documentales simples" (definiciones, contexto) ‚Üí **Weaviate**
     - **"Documentales complejas" (legales, multi-documento) ‚Üí PageIndex + Weaviate**
     - "H√≠bridas" (datos + contexto legal) ‚Üí **Cube Core + PageIndex + Weaviate**

   **Reglas de clasificaci√≥n actualizadas**:

   | Patr√≥n de Consulta | Ruta | Ejemplo |
   |---|---|---|
   | N√∫meros, m√©tricas, agregaciones | Cube Core | "¬øEBITDA de Q3 2024?" |
   | Comparaciones, ratios, tendencias | Cube Core | "¬øCreci√≥ revenue YoY?" |
   | Definiciones, contexto textual | Weaviate | "¬øC√≥mo se calcula EBITDA?" |
   | **Art√≠culos, cl√°usulas, leyes** | **PageIndex** | **"¬øQu√© art√≠culos del ISR aplican?"** |
   | **Contratos, actas, estructura legal** | **PageIndex** | **"¬øRiesgos fiscales de esta cl√°usula?"** |
   | Datos + explicaci√≥n contextual | Cube + Weaviate | "Explica c√≥mo se calcul√≥ el margen" |
   | **Datos + contexto legal** | **Cube + PageIndex** | **"Impacto fiscal de esta estructura"** |

3. **Ejecuci√≥n Determinista** (Cube Core + DuckDB):
   - Capa sem√°ntica genera SQL can√≥nico.
   - DuckDB ejecuta, resultado es trazable y reproducible.

4. **Recuperaci√≥n Documental** (PageIndex + Weaviate):
   - **PageIndex**: Razonamiento sobre estructura ‚Üí identifica secciones relevantes.
   - **Weaviate**: B√∫squeda vectorial filtrada por `page_index` ‚Üí recupera chunks espec√≠ficos.

5. **Capa de Explicaci√≥n** (Dify):
   - Recibe resultados deterministas + contexto curado.
   - Genera explicaciones en lenguaje natural.
   - **Principio cr√≠tico**: Solo explica, nunca decide rutas ni genera SQL.

6. **Visualizaci√≥n Determinista** (Chainlit):
   - Renderiza SQL visible, DataFrames, gr√°ficos Plotly.
   - `cl.Step` registra trazabilidad completa.

**Diagrama de flujo actualizado**:

```mermaid
graph TB
    User[Usuario] --> Chainlit[Chainlit Frontend]
    Chainlit --> n8n[n8n Router]

    n8n --> Router{Clasificaci√≥n}

    Router -->|Num√©rica| CubeCore[Cube Core]
    Router -->|Documental Simple| Weaviate[Weaviate]
    Router -->|Documental Compleja| PageIndex[PageIndex API]
    Router -->|H√≠brida| Hybrid[Cube + PageIndex]

    CubeCore --> DuckDB --> MinIO

    PageIndex -->|page_indices + summaries| Weaviate
    Weaviate -->|Chunks filtrados| Dify

    CubeCore --> Dify[Dify Explicaci√≥n]
    Hybrid --> Dify

    Dify --> Chainlit
```

### 4.10 Paradigma Headless BI

**Definici√≥n**: Arquitectura donde la capa sem√°ntica act√∫a como "API of Truth" y la UI es intercambiable.

**Beneficio para esta Investigaci√≥n**:
- **Chainlit** (frontend Python-first) sirve como consola anal√≠tica para usuarios finales con visualizaci√≥n determinista (DataFrames, SQL, Plotly).
- El mismo backend Cube Core alimenta scripts Python para ejecuci√≥n masiva de benchmarks.
- **Resultado**: Coherencia entre experimentaci√≥n acad√©mica y aplicaci√≥n pr√°ctica.

---

## 5. Objetivos

### Objetivo General
Dise√±ar, implementar y evaluar una arquitectura que reduzca significativamente las alucinaciones num√©ricas en sistemas de IA Generativa financiera, utilizando una capa sem√°ntica intermedia y validaci√≥n determinista.

### Objetivos Espec√≠ficos
1. **Implementar Capa Sem√°ntica:** Configurar **Cube Core** para definir m√©tricas financieras estandarizadas, sirviendo como "Single Source of Truth" (SSOT) para el LLM. Objetivo: garantizar que cada consulta sobre FP&A devuelve datos consistentes y auditables.
2. **Pipeline de Ingesta Estructural:** Utilizar **Docling** para procesar documentos financieros complejos (PDFs, Excel), preservando la estructura tabular para su an√°lisis SQL con estrategia de chunking sem√°ntico. Objetivo: automatizar la carga de reportes sin p√©rdida de integridad de datos.
3. **Validaci√≥n con Benchmarks Reales:** Evaluar la precisi√≥n de ejecuci√≥n (Execution Accuracy) utilizando datasets est√°ndar de la industria como **Spider**, **BIRD** y **FinQA**, demostrando que la arquitectura no es solo acad√©mica sino pr√°cticamente viable.
4. **Infraestructura H√≠brida:** Demostrar la viabilidad de una arquitectura distribuida (Cloud ARM + On-Premise x86) gestionada centralmente, validando que no requiere un "data center gigante" para implementarse.
5. **M√©tricas de √âxito Cuantificables:** Reducir significativamente las alucinaciones aritm√©ticas observadas en enfoques Text-to-SQL directos (baseline ~40% Execution Accuracy reportado en literatura), con un objetivo experimental de <5% de tasa de error medido mediante Execution Accuracy en benchmarks est√°ndar validados. **Objetivo de negocio:** proporcionar un FP&A Copilot que CFOs y analistas puedan usar con confianza, eliminando horas de retrabajo en validaci√≥n manual.
6. **Evaluar Capa de Explicaci√≥n:** Medir el impacto de Dify en la consistencia de explicaciones, latencia adicional introducida, y calidad de las narrativas generadas, manteniendo invariabilidad de los resultados num√©ricos.
7. **[NUEVO] Evaluar PageIndex:** Medir la mejora en precisi√≥n de recuperaci√≥n documental (Page Boundary Precision), trazabilidad de fuente (Citation Traceability) y reducci√≥n de context fragmentation vs. chunking tradicional.

---

## 6. Metodolog√≠a

### 6.1 Dise√±o Experimental

El estudio sigue un enfoque cuantitativo comparativo con tres configuraciones:

1. **Baseline**: LLM directo (Llama 3.1 70B, Mistral Large) ejecutando Text-to-SQL sin capa sem√°ntica.
2. **RAG Tradicional**: LLM + Embeddings + Vector DB (Weaviate) generando SQL estoc√°stico con chunking tradicional.
3. **SDRAG (Propuesto)**: LLM + Cube Core + PageIndex + Weaviate + Dify (arquitectura determinista con navegaci√≥n jer√°rquica y explicaci√≥n controlada).

### 6.2 M√©tricas de Evaluaci√≥n

#### 6.2.1 M√©tricas Primarias
- **Execution Accuracy (EX)**: Coincidencia exacta entre resultado num√©rico esperado (ground truth del benchmark) y resultado obtenido por el sistema. Medida principal para validar reducci√≥n de alucinaciones aritm√©ticas.
- **Query Routing Accuracy**: Porcentaje de consultas correctamente clasificadas como sem√°nticas (Cube Core) vs. documentales (Weaviate) vs. documentales complejas (PageIndex). Valida efectividad de la clasificaci√≥n determin√≠stica.
- **Numerical Hallucination Rate**: Porcentaje de respuestas con error aritm√©tico detectable (discrepancia >0.01% en valores num√©ricos). M√©trica inversa a Execution Accuracy.

#### 6.2.2 M√©tricas Secundarias
- **Latency End-to-End**: Tiempo desde input del usuario hasta respuesta completa renderizada en Chainlit (p50, p95, p99). Objetivo: <2s para queries simples.
- **Reproducibilidad**: Varianza de resultados ante m√∫ltiples ejecuciones id√©nticas (mismo input, misma configuraci√≥n). M√©trica clave para validar determinismo arquitect√≥nico.
- **Traceability Completeness**: Porcentaje de consultas con SQL visible, datos auditables y pasos ejecutados documentados v√≠a `cl.Step`.
- **Explanation Consistency (Dify)**: Variabilidad de explicaciones generadas por Dify ante mismo input determinista (medida con BLEU/ROUGE entre ejecuciones m√∫ltiples). M√©trica secundaria que no afecta validez de c√°lculos.
- **LLM Latency Overhead**: Tiempo adicional introducido por Dify en el flujo (medido como: latency total - latency c√°lculo determinista). Eval√∫a costo de explicaci√≥n en lenguaje natural.

#### 6.2.3 M√©tricas de RAG Documental
- **Document RAG Activation Rate**: % de consultas que activan recuperaci√≥n documental (solo para intenciones explicativas: define, explain, how is calculated).
- **Retrieval Precision**: Relevancia de chunks recuperados vs. ground truth (cuando disponible).
- **Context Utilization**: % de contexto recuperado efectivamente utilizado en la explicaci√≥n generada.

#### 6.2.4 M√©tricas de PageIndex (NUEVO)
- **Tree Search Accuracy**: Porcentaje de secciones correctamente identificadas por PageIndex vs. ground truth.
- **Page Boundary Precision**: Exactitud de `page_index` (start/end) respecto a contenido relevante real.
- **Reasoning Path Traceability**: Completitud del camino de navegaci√≥n en el √°rbol (n√∫mero de nodos visitados, decisiones razonadas).
- **PageIndex-Weaviate Alignment**: Consistencia entre secciones identificadas por PageIndex y chunks recuperados por Weaviate.
- **Citation Traceability**: % de respuestas con citas precisas a secci√≥n/p√°gina espec√≠fica.
- **Cross-reference Resolution Accuracy**: Exactitud en resoluci√≥n de relaciones entre documentos.

### 6.3 Reglas de Activaci√≥n de RAG Documental

**RAG Documental (Weaviate)** se activa cuando la consulta contiene patrones sem√°nticos de tipo explicativo:
- Patrones de activaci√≥n: "c√≥mo se calcula", "definici√≥n de", "explica el concepto de", "qu√© es", "c√≥mo se determina", "qu√© dice el reporte".
- Patrones de desactivaci√≥n: consultas puramente num√©ricas, comparaciones cuantitativas, solicitudes de c√°lculo directo.

**RAG Documental Complejo (PageIndex + Weaviate)** se activa cuando la consulta contiene:
- Patrones legales: "art√≠culo", "cl√°usula", "secci√≥n", "t√≠tulo", "cap√≠tulo", "Ley del ISR", "c√≥digo fiscal", "reglamento".
- Patrones contractuales: "contrato", "acta", "escritura", "convenio".
- Patrones de riesgo: "riesgo fiscal", "impacto legal", "precedente", "obligaciones fiscales".
- Relaciones sem√°nticas: "relaciona con", "aplica a", "deriva de", "estructura contractual".

Esta regla es **implementada en n8n** mediante clasificador ligero, no mediante LLM, garantizando trazabilidad y reproducibilidad.

### 6.4 Protocolo de Validaci√≥n

Para cada benchmark, se ejecutar√°n:
1. **Fase de Conversi√≥n**: Transformaci√≥n a formato Parquet/DuckDB en DuckLake (procesamiento distribuido con Dask).
2. **Fase de Ingesta**:
   - Indexaci√≥n de documentos no estructurados en Weaviate.
   - **[NUEVO]** Generaci√≥n de √≠ndices jer√°rquicos con PageIndex para documentos largos.
   - Definici√≥n de m√©tricas en Cube Core.
3. **Fase de Ejecuci√≥n**: 3 corridas por configuraci√≥n para medir reproducibilidad y consistencia de explicaciones.
4. **Fase de An√°lisis**: Comparaci√≥n de resultados, latencia, trazabilidad y calidad de explicaciones.

**Baseline Comparativo**:
1. LLM directo (sin capa sem√°ntica).
2. RAG tradicional (chunking est√°ndar sin PageIndex).
3. Human performance reportado en benchmarks (cuando disponible).

---

## 7. Infraestructura T√©cnica

### 7.1 Cluster Distribuido (Red Tailscale)

La red est√° unificada mediante **Tailscale**, permitiendo una operaci√≥n transparente entre la nube y el laboratorio local.

#### 7.1.1 Nodo 1: Oracle Cloud (ARM64, Orquestador)
- **Hardware**: VM.Standard.A1.Flex - ARM Neoverse-N1 (4 cores), 24 GB RAM con ECC, 45 GB Block Volume (sistema) + 151 GB Block Volume (datos).
- **Software**: Coolify (plano de control), n8n (router de consultas), Chainlit (frontend determinista), Dask Scheduler (coordinador de procesamiento distribuido).
- **Acceso**: IP p√∫blica para https://sdrag.com.

#### 7.1.2 Nodo 2: Mac Mini (Almacenamiento + RAG Documental)
- **Hardware**: Intel i5-3210M, 16 GB RAM, 1TB HDD (MinIO/DuckLake), 480GB SSD (Weaviate).
- **Software**: MinIO (DuckLake), **Weaviate** (√∫nica base de datos vectorial), Dify (capa de explicaci√≥n LLM), Dask Worker.
- **Rol de Weaviate**: Base de datos vectorial √∫nica para RAG sobre documentos no estructurados. Almacena embeddings, texto de documentos financieros, definiciones de m√©tricas, reglas de negocio, y **referencias a nodos PageIndex**. Provee b√∫squeda h√≠brida (vectorial + BM25). **Importante**: Weaviate **nunca** devuelve valores num√©ricos como verdad. Solo provee contexto documental para enriquecer explicaciones. Los n√∫meros son exclusivamente provistos por Cube Core.
- **Rol de Dify**: Servicio exclusivo de **explicaci√≥n en lenguaje natural**. Recibe resultados deterministas de Cube Core y contexto de Weaviate/PageIndex, generando narrativas comprensibles. **No participa** en clasificaci√≥n de consultas, generaci√≥n de SQL ni decisiones de enrutamiento.
- **Uptime t√≠pico**: 8+ d√≠as.

#### 7.1.3 Nodo 3: Dell Vostro (C√≥mputo)
- **Hardware**: Intel i5-7200U, 32 GB RAM, 915GB SSD.
- **Software**: Ollama (inferencia de modelos locales), Cube Core (capa sem√°ntica), Dask Worker (ETL distribuido), Docling (procesamiento de documentos), **[Futuro] PageIndex local** (auto-hospedado).
- **Rol**: Nodo principal de trabajo pesado y desarrollo local.

### 7.2 Stack de Software

- **Gesti√≥n de Dependencias**: `uv` (Astral) para entornos Python reproducibles y r√°pidos.
- **Motor Anal√≠tico**: **DuckDB** (OLAP en memoria).
- **Procesamiento Distribuido**: **Dask** (cluster de 3 nodos: Oracle Scheduler + Dell/Mac Workers).
- **Base de Datos Vectorial**: **Weaviate** (√∫nica - b√∫squeda h√≠brida vectorial + BM25).
- **Indexaci√≥n Jer√°rquica**: **PageIndex** (navegaci√≥n documental basada en razonamiento - MCP Server Local).
- **Capa de Explicaci√≥n LLM**: **Dify** (Language Explanation Service - solo post-c√°lculo).
- **Interfaz Determinista**: **Chainlit** (Frontend Python-first con visualizaci√≥n de DataFrames, SQL y gr√°ficos Plotly).
- **Orquestaci√≥n**: **n8n** (Motor expl√≠cito de control de flujo determinista, permitiendo auditar decisiones de enrutamiento que en sistemas LLM-driven suelen ser impl√≠citas y opacas).
- **Capa Sem√°ntica**: **Cube Core** (Seleccionado por: caching y pre-aggregations nativas, API headless lista para consumo LLM, m√©tricas versionadas y auditables, separaci√≥n clara entre definici√≥n sem√°ntica y ejecuci√≥n; Redis para caching y coordinaci√≥n; pre-aggregations materializadas en storage compatible S3).

---

## 8. Cronograma

### ‚úÖ Semestre 1: Definici√≥n y Arquitectura (Completado)
* Revisi√≥n del estado del arte (RAG, Text-to-SQL, Semantic Layers).
* Dise√±o de la arquitectura de hardware y red (Cluster `sdrag.com`).
* Selecci√≥n del stack tecnol√≥gico (Cube, Docling, Coolify).

### üöß Semestre 2: Implementaci√≥n del Core (En Progreso)
* Despliegue de **cluster Dask distribuido** (Scheduler en Oracle Cloud, Workers en Dell + Mac Mini).
* Despliegue y configuraci√≥n de **Cube Core** y **MinIO** (DuckLake).
* Despliegue de **Dify** en Mac Mini como capa de explicaci√≥n LLM (post-c√°lculo).
* Despliegue de **Weaviate** como √∫nica base de datos vectorial para RAG documental.
* **[NUEVO]** Despliegue de **PageIndex MCP Server Local** para indexaci√≥n jer√°rquica de documentos largos sin limitaciones.
* Desarrollo del pipeline de ingesta ETL con **Docling** y **Dask** (procesamiento paralelo de benchmarks).
* Conversi√≥n completa de Benchmarks (**Spider**, **BIRD**, **FinQA**) a formato Parquet/DuckDB en DuckLake (~65-80 GB totales) usando procesamiento distribuido (speedup estimado: 4x vs. secuencial).
* Implementaci√≥n de estrategia de chunking sem√°ntico (HybridChunker) con Œ∏=0.8 para preservar estructura de tablas.
* **[NUEVO]** Generaci√≥n de √≠ndices jer√°rquicos con PageIndex para documentos financieros y legales en benchmarks relevantes (FinanceBench, TAT-QA).
* Pruebas iniciales de conexi√≥n LLM ‚Üí Capa Sem√°ntica.
* **Integraci√≥n de Dify**: Implementaci√≥n de flujo n8n ‚Üí Dify ‚Üí n8n para generaci√≥n controlada de explicaciones en lenguaje natural.
* **Integraci√≥n PageIndex-Weaviate (MCP Local)**: Creaci√≥n de clase `PageIndexReference` y pipeline de sincronizaci√≥n con MCP server local.
* **M√©tricas de Performance**: Reducci√≥n de ~30 horas ‚Üí ~10 horas por ciclo completo de experimentaci√≥n (conversi√≥n + procesamiento + embeddings).

### üìÖ Semestre 3: Orquestaci√≥n y Refinamiento
* Implementaci√≥n de flujos de routing en **n8n** (clasificaci√≥n sem√°ntica vs. documental simple vs. documental compleja).
* **[NUEVO]** Desarrollo de l√≥gica de enrutamiento para consultas legales/complejas hacia PageIndex.
* Desarrollo de l√≥gica de enrutamiento para consultas h√≠bridas.
* Refinamiento de la interfaz **Chainlit** con visualizaciones deterministas (DataFrames, SQL, Plotly).
* Optimizaci√≥n de latencia end-to-end (objetivo: <2s para queries simples, <5s para queries con PageIndex).
* Integraci√≥n de `cl.Step` para trazabilidad completa de ejecuci√≥n incluyendo decisiones de PageIndex.
* **Evaluaci√≥n de Dify**: Medici√≥n de consistencia de explicaciones, latencia overhead y comparaci√≥n entre diferentes modelos LLM.
* **[NUEVO] Evaluaci√≥n de PageIndex**: Medici√≥n de Page Boundary Precision, Citation Traceability, y mejora en relevancia vs. chunking tradicional.

### üìÖ Semestre 4: Evaluaci√≥n y Defensa
* Ejecuci√≥n de benchmarks comparativos (LLM solo vs. LLM + Cube vs. SDRAG completo con PageIndex).
* Medici√≥n de latencia, precisi√≥n y tasa de alucinaci√≥n.
* An√°lisis de trade-offs entre consistencia de explicaciones y variabilidad estoc√°stica del LLM.
* **[NUEVO]** An√°lisis comparativo de recuperaci√≥n documental: chunking tradicional vs. PageIndex.
* Redacci√≥n de tesis y defensa final.

---

## 9. Datasets de Validaci√≥n

Para asegurar el rigor cient√≠fico, el sistema ser√° evaluado utilizando:

### Text-to-SQL Benchmarks
* **Spider (2018):** 10,181 pares pregunta-SQL, 200 bases de datos (~5 GB). Dataset de referencia para Text-to-SQL con baseline establecido (~40% Execution Accuracy sin capa sem√°ntica).
* **BIRD (2023):** 12,751 ejemplos, 95 bases de datos (33.4 GB). Dataset realista con datos "sucios" y conocimiento externo, representando escenarios corporativos complejos.
* **WikiSQL (2017):** 80,654 ejemplos, 24,241 tablas (~3 GB). Queries SQL simples (SELECT + WHERE), √∫til para validar capacidades b√°sicas de la capa sem√°ntica.

### Financial Reasoning Benchmarks
* **FinQA (2021):** Dataset de razonamiento num√©rico financiero (~1 GB). Validaci√≥n espec√≠fica de operaciones aritm√©ticas sobre reportes financieros (P&L, Balance Sheet).
* **TAT-QA (2021):** 16,552 preguntas sobre 2,757 reportes financieros (~2 GB). QA h√≠brido (tablas + texto) requiriendo numerical reasoning (suma, resta, comparaci√≥n). Human performance: 84.1% F1. **[PageIndex aplicable]**: Documentos largos con estructura compleja.
* **FinanceBench (2023):** 150 ejemplos human-annotated con ground truth (~500 MB). Revela que GPT-4-Turbo con RAG falla 81% de preguntas financieras, justificando necesidad de capa sem√°ntica. **[PageIndex aplicable]**: Reportes anuales complejos (10K, 20-F).
* **ConvFinQA (2022):** QA conversacional financiero requiriendo c√°lculos multi-hop (~800 MB). Eval√∫a capacidad de mantener contexto en di√°logos financieros.

### Table Reasoning Benchmarks
* **WikiTableQuestions (2015):** Preguntas complejas sobre tablas de Wikipedia (~1 GB). Eval√∫a comprensi√≥n de estructuras tabulares.
* **SQA (Sequential QA, 2017):** 6,066 secuencias de preguntas (~500 MB). Valida capacidad de razonamiento multi-turno sobre tablas.

### **Benchmarks RAG Documental Multi-Documento**

Para validar las capacidades espec√≠ficas de PageIndex + Weaviate en razonamiento multi-documento, se emplear√° una estrategia de evaluaci√≥n en 3 fases:

#### **Fase 1: Benchmarks P√∫blicos (Baseline acad√©mico)**
* **LegalBench-RAG:** 6,858 pares pregunta-respuesta, corpus 79M caracteres, human-annotated por expertos legales. **Uso como baseline para establecer capacidades legales b√°sicas, no como objetivo final**.
* **MultiHop-RAG:** 2,556 queries con evidencia distribuida across 2-4 documentos. Eval√∫a inference queries, comparison queries, temporal queries y cross-document reasoning. **Benchmark core para justificar PageIndex + Weaviate**.
* **FinMMDocR:** 1,200 problemas expert-annotated, 837 documentos. **Eval√∫a interpretaci√≥n y contexto documental financiero, no c√°lculos num√©ricos** (responsabilidad exclusiva de Cube Core).

#### **Fase 2: Dataset Sint√©tico Espec√≠fico (Diferenciador acad√©mico)**
* **Legal-Financial Hybrid:** Casos que requieren navegar entre Ley del ISR + contratos + estados financieros. **Justifica arquitectura h√≠brida** (Cube para n√∫meros, PageIndex+Weaviate para contexto legal).
* **Mexican Tax Code (ISR + Contratos):** Casos espec√≠ficos de compliance fiscal mexicano. **No eval√∫a interpretaci√≥n legal definitiva, sino consistencia y trazabilidad** en el reasoning.
* **Corporate Compliance:** Relaci√≥n actas corporativas + obligaciones fiscales. Eval√∫a **compliance reasoning**, no solo b√∫squeda.

#### **Fase 3: Validaci√≥n Experta (Rigor profesional)**
* **Human Annotation (CPAs/Abogados):** Evaluaci√≥n con criterios espec√≠ficos: Correctness (1-5), Traceability (1-5), Completeness (1-5), Hallucination Risk (1-5).
* **Citation Verification:** % citas v√°lidas, % citas verificables, profundidad de referencia (art√≠culo vs secci√≥n). **Justifica PageIndex y castiga hallucinations**.
* **Business Impact (Estudio Exploratorio):** Medici√≥n de reducci√≥n de tiempo en research legal en muestra peque√±a y escenarios controlados. **Evidencia pr√°ctica, no estad√≠stica dura**.

#### **M√©tricas Transversales**
* **Cross-Document Recall:** % de documentos relevantes recuperados por query multi-documento
* **Relational Recall:** % de relaciones correctas identificadas entre documentos (ej: cl√°usula contractual ‚Üî art√≠culo fiscal)
* **Cross-Reference Precision:** % de referencias cruzadas correctamente enlazadas entre documentos legales
* **Reasoning Chain Completeness:** Completitud de cadena de razonamiento cross-document
* **Source Coverage:** % de fuentes necesarias identificadas para resolver consulta h√≠brida
* **Page_Boundary_Precision:** Precisi√≥n espec√≠fica de navegaci√≥n jer√°rquica PageIndex
* **Citation_Traceability:** Trazabilidad de fuentes en explicaciones generadas por Dify

#### **Limitaciones Expl√≠citas de la Evaluaci√≥n**
**Importante para defensa acad√©mica:** Esta evaluaci√≥n **NO incluye**:
- ‚ùå **Interpretaci√≥n legal definitiva:** No reemplaza asesor√≠a legal profesional
- ‚ùå **C√°lculos financieros en RAG:** Los n√∫meros provienen exclusivamente de Cube Core
- ‚ùå **Validez jur√≠dica:** Solo eval√∫a consistencia t√©cnica y trazabilidad
- ‚ùå **Escalabilidad industrial:** Se enfoca en precisi√≥n y reproducibilidad acad√©mica
- ‚úÖ **S√≠ eval√∫a:** Coherencia documental, trazabilidad de fuentes, reasoning multi-hop

**Almacenamiento Total Estimado:** ~80-95 GB (Parquet + embeddings + √≠ndices PageIndex) alojados en DuckLake (MinIO en Mac Mini 1TB).

---

## 10. Filosof√≠a del Proyecto: "Business Outcomes First"

Esta tesis rechaza el enfoque tradicional acad√©mico que separa la "viabilidad t√©cnica" del "impacto real". Cada componente debe justificar su existencia respondiendo: **¬øQu√© problema de negocio resuelve esto?**

Los departamentos de FP&A corporativos sufren de:
- **Errores aritm√©ticos** recurrentes que requieren validaci√≥n manual
- **Inconsistencias** en definiciones de m√©tricas entre reportes
- **Retrabajo cr√≥nico** en cada ciclo de cierre contable
- **Desconfianza ejecutiva** en los n√∫meros ("¬øeste n√∫mero es correcto?")
- **[NUEVO]** Dificultad para navegar documentos legales complejos (leyes, contratos, actas)
- **[NUEVO]** Incapacidad de relacionar cl√°usulas contractuales con obligaciones fiscales

Esta tesis propone una arquitectura que resuelve estos problemas mediante una **Capa Sem√°ntica como √Årbitro Determinista** y **PageIndex como Navegador Documental Inteligente**. No es un "experimento de laboratorio bonito" ‚Äî es una herramienta que FP&A departments pueden usar hoy para mejorar su eficiencia y confiabilidad.

**Mandato de la investigaci√≥n:** "¬øCu√°l es la arquitectura m√≠nima que le permite a un CFO confiar en los n√∫meros **y** entender el contexto legal/contractual de sus decisiones?" Una vez respondida, todo lo dem√°s es implementaci√≥n.

---

## 11. Limitaciones del Sistema

Esta implementaci√≥n prioriza rigor experimental y reproducibilidad sobre escalabilidad industrial completa:

- **No implementa alta disponibilidad (HA)** ni replicaci√≥n multi-nodo de storage para producci√≥n 24/7.
- **No aborda escenarios multi-tenant** ni control de costos a gran escala con cientos de usuarios concurrentes.
- **El enfoque se centra en precisi√≥n y trazabilidad**, no en auto-scaling din√°mico de inferencia o elasticidad cloud.
- **Infraestructura h√≠brida limitada** a recursos disponibles (3 nodos f√≠sicos), sin redundancia geogr√°fica.
- **Weaviate no genera n√∫meros**: Solo provee contexto documental (texto, referencias, definiciones). Los n√∫meros son exclusivamente provistos por Cube Core.
- **GraphRAG limitado a 1-2 saltos**: Razonamiento multi-hop complejo queda fuera del alcance, priorizando simplicidad verificable.
- **Dify es una capa controlada**: Aunque introduce variabilidad estoc√°stica en las explicaciones (inherente a los LLMs), esta variabilidad **no afecta los resultados num√©ricos** que son inmutables al llegar a Dify. La consistencia de explicaciones se evaluar√° como m√©trica secundaria, pero no compromete la validez de los c√°lculos.
- **[NUEVO] PageIndex introduce latencia adicional**: Tree search razonado requiere m√∫ltiples iteraciones con LLM (2-5s por query), m√°s lento que similarity search pura (<1s). Trade-off aceptable para documentos complejos donde precisi√≥n > velocidad.
- **[NUEVO] PageIndex MCP Local**: Sin l√≠mites de volumen ni costos adicionales. Procesamiento totalmente local garantiza privacidad completa de documentos.
- **[NUEVO] PageIndex no reemplaza Cube Core**: Solo mejora navegaci√≥n documental. La arquitectura determin√≠stica para c√°lculos num√©ricos permanece sin cambios.

Estas limitaciones **no invalidan los resultados**, ya que el objetivo de la investigaci√≥n es evaluar la reducci√≥n de alucinaciones mediante dise√±o arquitect√≥nico, no construir un sistema enterprise completo. La arquitectura propuesta es **escalable conceptualmente** y puede adaptarse a entornos de producci√≥n con recursos adicionales.

---

## 12. Bibliograf√≠a (Selecci√≥n)

* Chen, M., et al. (2025). *Reliable Text-to-SQL with Adaptive Abstention*. arXiv.
* Finegan-Dollak, C., et al. (2018). *Improving Text-to-SQL Evaluation Methodology*. ACL.
* Gong, S., et al. (2025). *SQLens: An End-to-End Framework for Error Detection and Correction in Text-to-SQL*. arXiv.
* Guo, W., et al. (2025). *SQLForge: Synthesizing Reliable and Diverse Data to Enhance Text-to-SQL Reasoning in LLMs*. arXiv.
* Li, Z., et al. (2023). *FinanceBench: A Benchmark for Evaluating LLMs in Financial Question Answering*. arXiv.
* OpenAI. (2023). *GPT-4 Technical Report*.
* Taori, R., et al. (2023). *Alpaca: A Strong, Replicable Instruction-Following Model*. Stanford CRFM.
* VectifyAI. (2025). *PageIndex: Vectorless RAG with Hierarchical Tree Search*. GitHub Repository.
* Wei, J., et al. (2023). *Chain-of-Thought Prompting Elicits Reasoning in Large Language Models*. NeurIPS.
* Yao, S., et al. (2023). *ReAct: Synergizing Reasoning and Acting in Language Models*. ICLR.

---

*Documento generado el 19 de enero de 2026. Versi√≥n 8 con incorporaci√≥n de PageIndex. Propiedad intelectual del autor, H√©ctor Gabriel S√°nchez P√©rez.*
